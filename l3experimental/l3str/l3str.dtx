% \iffalse meta-comment
%
%% File: l3str.dtx Copyright (C) 2011 The LaTeX3 Project
%%
%% It may be distributed and/or modified under the conditions of the
%% LaTeX Project Public License (LPPL), either version 1.3c of this
%% license or (at your option) any later version.  The latest version
%% of this license is in the file
%%
%%    http://www.latex-project.org/lppl.txt
%%
%% This file is part of the "l3experimental bundle" (The Work in LPPL)
%% and all files in that bundle must be distributed together.
%%
%% The released version of this bundle is available from CTAN.
%%
%% -----------------------------------------------------------------------
%%
%% The development version of the bundle can be found at
%%
%%    http://www.latex-project.org/svnroot/experimental/trunk/
%%
%% for those people who are interested.
%%
%%%%%%%%%%%
%% NOTE: %%
%%%%%%%%%%%
%%
%%   Snapshots taken from the repository represent work in progress and may
%%   not work or may contain conflicting material!  We therefore ask
%%   people _not_ to put them into distributions, archives, etc. without
%%   prior consultation with the LaTeX3 Project.
%%
%% -----------------------------------------------------------------------
%
%<*driver|package>
\RequirePackage{expl3}
\GetIdInfo$Id$
  {L3 Experimental Strings}
%</driver|package>
%<*driver>
\documentclass[full]{l3doc}
\usepackage{amsmath}
\begin{document}
  \DocInput{\jobname.dtx}
\end{document}
%</driver>
% \fi
%
%
% \title{^^A
%   The \textsf{l3str} package: manipulating strings of characters^^A
%   \thanks{This file describes v\ExplFileVersion,
%     last revised \ExplFileDate.}^^A
% }
%
% \author{^^A
%  The \LaTeX3 Project\thanks
%    {^^A
%      E-mail:
%        \href{mailto:latex-team@latex-project.org}
%          {latex-team@latex-project.org}^^A
%    }^^A
% }
%
% \date{Released \ExplFileDate}
%
% \maketitle
%
% \begin{documentation}
%
% \LaTeX3 provides a set of functions to manipulate token lists
% as strings of characters, ignoring the category codes of those
% characters.
%
% String variables are simply specialised token lists, but by convention
% should be named with the suffix \texttt{\ldots str}. Such variables should
% contain characters with category code $12$ (other), except spaces, which
% have category code $10$ (blank space). All the \enquote{safe} functions in
% this module first convert their argument to a string for internal processing,
% and will not treat a token list or the corresponding string representation
% differently.
%
% Most functions in this module come in three flavours:
% \begin{itemize}
%   \item \cs{str_...:N...}, which expect a token list
%     variable as their argument;
%   \item \cs{str_...:n...}, taking any token list (or string) as an argument;
%   \item \cs{str_..._ignore_spaces:n...}, which ignores any space encountered
%     during the operation: these functions are faster than those
%     which take care of escaping spaces appropriately;
% \end{itemize}
% When performance is important, the internal \cs{str_..._unsafe:n...}
% functions, which expect a \enquote{safe} string in which spaces
% have category code $12$ instead of $10$, might be useful.
%
% \section{Conversion and input of strings}
%
% \begin{variable}
%   {
%     \c_backslash_str,
%     \c_lbrace_str,
%     \c_rbrace_str,
%     \c_hash_str,
%     \c_tilde_str,
%     \c_percent_str
%   }
%   Constant strings, containing a single character, with category code $12$.
% \end{variable}
%
% \begin{function}[EXP]{\tl_to_str:N, \tl_to_str:n}
%   \begin{syntax}
%     \cs{tl_to_str:N} \meta{tl var}
%     \cs{tl_to_str:n} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string}, leaving the resulting
%   tokens in the input stream.
% \end{function}
%
% \begin{function}{\str_const:Nn, \str_const:Nx, \str_const:cn, \str_const:cx}
%   \begin{syntax}
%     \cs{str_const:Nn} \meta{str~var} \Arg{token list}
%   \end{syntax}
%   Creates a new constant \meta{str~var} or raises an error
%   if the name is already taken. The value of the
%   \meta{str~var} will be set globally to the
%   \meta{token list}, after being converted to a string.
% \end{function}
%
% \begin{function}{\str_set:Nn, \str_set:Nx, \str_set:cn, \str_set:cx}
%   \begin{syntax}
%     \cs{str_set:Nn} \meta{str var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and saves the result in \meta{str var}.
% \end{function}
%
% \begin{function}{\str_gset:Nn, \str_gset:Nx, \str_gset:cn, \str_gset:cx}
%   \begin{syntax}
%     \cs{str_gset:Nn} \meta{str~var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and saves the result in \meta{str~var} globally.
% \end{function}
%
% \begin{function}
%   {
%     \str_put_left:Nn, \str_put_left:Nx,
%     \str_put_left:cn, \str_put_left:cx
%   }
%   \begin{syntax}
%     \cs{str_put_left:Nn} \meta{str var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and prepends the result to \meta{str var}.
%   The current contents of the \meta{str var} are not
%   automatically converted to a string.
% \end{function}
%
% \begin{function}
%   {
%     \str_gput_left:Nn, \str_gput_left:Nx,
%     \str_gput_left:cn, \str_gput_left:cx
%   }
%   \begin{syntax}
%     \cs{str_gput_left:Nn} \meta{str var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and prepends the result to \meta{str var}, globally.
%   The current contents of the \meta{str var} are not
%   automatically converted to a string.
% \end{function}
%
% \begin{function}
%   {
%     \str_put_right:Nn, \str_put_right:Nx,
%     \str_put_right:cn, \str_put_right:cx
%   }
%   \begin{syntax}
%     \cs{str_put_right:Nn} \meta{str var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and appends the result to \meta{str var}.
%   The current contents of the \meta{str var} are not
%   automatically converted to a string.
% \end{function}
%
% \begin{function}
%   {
%     \str_gput_right:Nn, \str_gput_right:Nx,
%     \str_gput_right:cn, \str_gput_right:cx
%   }
%   \begin{syntax}
%     \cs{str_gput_right:Nn} \meta{str var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and appends the result to \meta{str var}, globally.
%   The current contents of the \meta{str var} are not
%   automatically converted to a string.
% \end{function}
%
% \begin{function}{\str_input:Nn, \str_ginput:Nn}
%   \begin{syntax}
%     \cs{str_input:Nn} \meta{str var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} into a \meta{string}, and stores
%   it in the \meta{str var}, within the current \TeX{} group level
%   for the \texttt{input} variant and globally for the \texttt{ginput}
%   version.
%   Special characters can be input by
%   escaping them with a backslash.
%   \begin{itemize}
%     \item Spaces are ignored unless escaped with a backslash.
%     \item |\xhh| produces the character with code \texttt{hh}
%       in hexadecimal: when |\x| is encountered, up to two hexadecimal digits
%       (\texttt{0}--\texttt{9}, \texttt{a}--\texttt{f},
%       \texttt{A}--\texttt{F})
%       are read to give a number between $0$ and $255$.
%     \item |\x{hh...}| produces the character with code \texttt{hh...}
%       (an arbitrary number of hexadecimal digits are read):
%       this is mostly useful for \LuaTeX{} and \XeTeX{}.
%     \item |\a|, |\e|, |\f|, |\n|, |\r|, |\t| stand for specific characters:
%     \begin{center}
%       \begin{tabular}{cccc}
%         |\a| & |\^^G| & alarm  & hex \texttt{07} \\
%         |\e| & |\^^[| & escape & hex \texttt{1B} \\
%         |\f| & |\^^L| & form feed & hex \texttt{0C} \\
%         |\n| & |\^^J| & new line  & hex \texttt{0A} \\
%         |\r| & |\^^M| & carriage return & hex \texttt{0D} \\
%         |\t| & |\^^I| & horizontal tab  & hex \texttt{09} \\
%       \end{tabular}
%     \end{center}
%   \end{itemize}
%   For instance,
%   \begin{quote}
%     \cs{tl_new:N} \cs{l_my_str} \\
%     \cs{str_input:Nn} \cs{l_my_str} |{\x3C \\ \# abc\ def\^\n}|
%   \end{quote}
%   results in \cs{l_my_str} containing the characters |<\#abc def^|,
%   followed by a newline character (hex \texttt{0A})
%   since |<| has \textsc{ascii} code \texttt{3C} (in hexadecimal).
% \end{function}
%
% \section{Characters given by their position}
%
% \begin{function}[EXP]
%   {\str_length:N, \str_length:n, \str_length_ignore_spaces:n}
%   \begin{syntax}
%     \cs{str_length:n} \Arg{token list}
%   \end{syntax}
%   Leaves the length of the string representation of \meta{token list}
%   in the input stream as an integer denotation. The functions differ in
%   their treatment of spaces.
%   In the case of \cs{str_length:N} and \cs{str_length:n},
%   all characters including spaces are counted.
%   The \cs{str_length_ignore_spaces:n} leaves the number of non-space
%   characters in the input stream.
%   \begin{texnote}
%     The \cs{str_length:n} of a given token list may depend
%     on the category codes in effect when it is measured,
%     and the value of the \tn{escapechar}: for instance
%     |\str_length:n {\a}| may return $1$, $2$ or $3$ depending
%     on the escape character, and the category code of \texttt{a}.
%   \end{texnote}
% \end{function}
%
% \begin{function}[EXP]{\str_head:N, \str_head:n, \str_head_ignore_spaces:n}
%   \begin{syntax}
%     \cs{str_head:n} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} into a \meta{string}.
%   The first character in the \meta{string} is then
%   left in the input stream, with category code \enquote{other}.
%   The functions differ in their treatment of spaces.
%   In the case of \cs{str_head:N} and \cs{str_head:n},
%   a leading space is returned with category code $10$ (blank space).
%   The \cs{str_head_ignore_spaces:n} function leaves  the first
%   non-space character in the input stream.
%   If the \meta{token list} is empty (or blank in the case of the
%   \texttt{_ignore_spaces} variant), then nothing is left on the
%   input stream.
% \end{function}
%
% \begin{function}[EXP]{\str_tail:N, \str_tail:n, \str_tail_ignore_spaces:n}
%   \begin{syntax}
%     \cs{str_tail:n} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   removes the first character, and leaves
%   the remaining characters (if any) in the input stream,
%   with category codes $12$ and $10$ (for spaces).
%   The functions differ in the case where the first character
%   is a space: \cs{str_tail:N} and \cs{str_tail:n} will trim
%   only that space, while \cs{str_tail_ignore_spaces:n} trims
%   the first non-space character.
% \end{function}
%
% \begin{function}[EXP]{\str_item:Nn, \str_item:nn, \str_item_ignore_spaces:nn}
%   \begin{syntax}
%     \cs{str_item:nn} \Arg{token list} \Arg{integer expression}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string}, and
%   leaves in the input stream the character in position
%   \meta{integer expression} of the \meta{string}.
%   In the case of \cs{str_item:Nn} and \cs{str_item:nn},
%   all characters including spaces are taken into account.
%   The \cs{str_item_ignore_spaces:nn} function skips spaces
%   in its argument.
%   If the \meta{integer expression} is negative, characters
%   are counted from the end of the \meta{string}. Hence, $-1$ is
%   the right-most character, \emph{etc.}, while $0$ is the first
%   (left-most) character.
% \end{function}
%
% \begin{function}[EXP]
%   {\str_substr:Nnn, \str_substr:nnn, \str_substr_ignore_spaces:nnn}
%   \begin{syntax}
%     \cs{str_substr:nnn} \Arg{token list} \Arg{start index} \Arg{end index}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string},
%   and leaves in the input stream the characters
%   between \meta{start index} (inclusive) and \meta{end index} (exclusive).
%   If either of \meta{start index} or \meta{end index} is negative,
%   then it is incremented by the length of the list. Both \meta{start index}
%   and \meta{end index} count from $0$ for the first (left most) character.
% \end{function}
%
% \section{String conditionals}
%
% \begin{function}[EXP, pTF]
%   {
%     \str_if_eq:NN,
%     \str_if_eq:nn, \str_if_eq:Vn, \str_if_eq:on, \str_if_eq:no,
%     \str_if_eq:nV, \str_if_eq:VV, \str_if_eq:xx
%   }
%   \begin{syntax}
%     \cs{str_if_eq_p:nn} \Arg{tl1} \Arg{tl2}
%     \cs{str_if_eq:nnTF} \Arg{tl1} \Arg{tl2} \Arg{true code} \Arg{false code}
%   \end{syntax}
%   Compares the two \meta{token lists} on a character by character
%   basis, and is \texttt{true} if the two lists contain the same
%   characters in the same order. Thus for example
%   \begin{verbatim}
%     \str_if_eq_p:xx { abc } { \tl_to_str:n { abc } }
%   \end{verbatim}
%   is logically \texttt{true}. All versions of these functions are fully
%   expandable (including those involving an \texttt{x}-type
%   expansion).
% \end{function}
%
% \begin{function}[EXP, pTF]{\str_if_bytes:N}
%   \begin{syntax}
%     \cs{str_if_bytes:NTF} \meta{str var} \Arg{true code} \Arg{false code}
%   \end{syntax}
%   Tests whether the \meta{str var} only contains characters
%   in the range $0$ to $255$. This is automatically true when
%   the pdf\TeX{} engine is in use.
% \end{function}
%
% \section{Encoding functions}
%
% Traditionally, string encodings only specify how strings of characters
% should be stored as bytes. However, the resulting lists of bytes are
% often to be used in contexts where only a restricted subset of bytes
% are permitted (\textsc{pdf} string objects, \textsc{url}s).
% Hence, storing strings of characters has two components.
% \begin{itemize}
% \item The code points (\enquote{character codes})
%   are expressed as bytes following a given
%   \enquote{encoding}. This can be \textsc{utf-16},
%   \textsc{iso 8859-1}, \emph{etc.}
%   See Table~\ref{tab:encodings} for a list
%   of encodings supported.
% \item Bytes are translated to \TeX{} tokens through
%   a given \enquote{escaping}. Those are defined for
%   the most part by the \texttt{pdf} file format.
%   See Table~\ref{tab:escapings} for a list
%   of escaping methods supported.
% \end{itemize}
%
% \begin{table}\centering
%   \caption{\label{tab:encodings}Supported encodings.}
%   \begin{tabular}{cc}
%     \toprule
%     \texttt{utf8}     & \textsc{utf-8} \\
%     \texttt{utf16}    & \textsc{utf-16}, with byte-order mark \\
%     \texttt{utf16be}  & \textsc{utf-16}, big-endian \\
%     \texttt{utf16le}  & \textsc{utf-16}, little-endian \\
%     \texttt{utf32}    & \textsc{utf-32}, with byte-order mark \\
%     \texttt{utf32be}  & \textsc{utf-32}, big-endian \\
%     \texttt{utf32le}  & \textsc{utf-32}, little-endian \\
%     \texttt{iso88591}, \texttt{latin1} & \textsc{iso 8859-1} \\
%     \midrule
%     \texttt{native}   & Native Unicode string. \\
%     \texttt{internal} & Comma-list of integers. \\
%     \bottomrule
%   \end{tabular}
% \end{table}
%
% \begin{table}\centering
%   \caption{\label{tab:escapings}Supported escapings.}
%   \begin{tabular}{cc}
%     \toprule
%     \texttt{bytes}, or empty
%       & arbitrary bytes \\
%     \texttt{hex}, \texttt{hexadecimal}
%       & byte $=$ two hexadecimal digits \\
%     \texttt{name}
%       & see \tn{pdfescapename} \\
%     \texttt{string}
%       & see \tn{pdfescapestring} \\
%     \texttt{url}, \texttt{percent}
%       & encoding used in \textsc{url}s \\
%     \bottomrule
%   \end{tabular}
% \end{table}
%
% \begin{function}{\str_set_convert:Nnnn}
%   \begin{syntax}
%     \cs{str_set_convert:Nnnn} \meta{str~var} \Arg{string}
%     ~~\Arg{name 1} \Arg{name 2}
%   \end{syntax}
%   This function converts the \meta{string} from the encoding
%   given by \meta{name 1} to the encoding given by \meta{name 2},
%   and stores the result in the \meta{str~var}.
%   Each \meta{name} can have the form \meta{encoding} or
%   \meta{encoding}\texttt{/}\meta{escaping}, where the possible values
%   of \meta{encoding} and \meta{escaping} are given in
%   Tables~\ref{tab:encodings} and~\ref{tab:escapings}, respectively.
%   The default escaping is to input and output bytes directly.
%   The special encodings \texttt{native} and \texttt{internal}
%   do not support a \meta{escaping}, since those formats do not
%   correspond to strings of bytes.
%
%   For example,
%   \begin{verbatim}
%     \str_set_convert:Nnnn \l_foo_str { Hello! }
%       { native } { utf16/hex }
%   \end{verbatim}
%   results in the variable \cs{l_foo_str} holding the string
%   \texttt{FEFF00480065006C006C006F0021}. This is obtained
%   by converting each character in the string \texttt{Hello!}
%   to the \textsc{utf-16} encoding, and expressing each byte
%   as a pair of hexadecimal digits. Note the presence of a
%   (big-endian) byte order mark \texttt{FEFF}, which can be
%   avoided by specifying the encoding \texttt{utf16be/hex}.
%
%   Parts of the \meta{string} which cannot be converted to bytes
%   using the \meta{escaping 1} are silently ignored (including non-byte
%   characters which could be present in the string).
%   Sequences of bytes which are not valid in the \meta{encoding 1}
%   are converted to the replacement character |"FFFD|, and raise
%   an error.
%   Characters which cannot be encoded in the \meta{encoding 2}
%   are silently ignored.
%^^A todo: add doc and examples about each encoding and escaping method.
% \end{function}
%
% \section{Internal string functions}
%
% \begin{function}[EXP]{\tl_to_other_str:N, \tl_to_other_str:n}
%   \begin{syntax}
%     \cs{tl_to_other_str:n} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to an \meta{other string}, where
%   spaces have category code \enquote{other}. These functions create
%   \enquote{safe} strings.
%   \begin{texnote}
%     These functions can be \texttt{f}-expanded without fear of losing
%     a leading space, since spaces do not have category code $10$ in
%     their result.
%   \end{texnote}
% \end{function}
%
% \begin{function}[EXP]{\str_sanitize_args:Nn, \str_sanitize_args:Nnn}
%   \begin{syntax}
%     \cs{str_sanitize_args:Nnn} \meta{function}
%     ~~\Arg{token list1} \Arg{token list2}
%   \end{syntax}
%   Converts the \meta{token lists} to \enquote{safe} strings
%   (where spaces have category code \enquote{other}),
%   and hands-in the result as arguments to \meta{function}.
% \end{function}
%
% \begin{function}{\str_aux_gset_other:Nn}
%   \begin{syntax}
%     \cs{str_aux_gset_other:Nn} \meta{tl~var} \Arg{token list}
%   \end{syntax}
%   Converts the \meta{token list} to an \meta{other string}, where
%   spaces have category code \enquote{other}, and assigns the result
%   to the \meta{tl~var}, globally.
% \end{function}
%
% \begin{function}[rEXP]{\str_map_tokens:Nn, \str_map_tokens:nn}
%   \begin{syntax}
%     \cs{str_map_tokens:Nn} \meta{str var} \meta{tokens}
%   \end{syntax}
%   Maps the \meta{tokens} over every character in the \meta{str var}.
% \end{function}
%
% \begin{function}[EXP, pTF]
%   {\str_if_contains_char:NN, \str_if_contains_char:nN}
%   \begin{syntax}
%     \cs{str_if_contains_char:nN} \Arg{token list} \meta{char}
%   \end{syntax}
%   Converts the \meta{token list} to a \meta{string}
%   and tests whether the \meta{char} is present in the \meta{string}.
%   The \meta{char} can be given either directly, or as a one
%   letter control sequence.
% \end{function}
%
% \begin{function}{\str_aux_escape:NNNn}
%   \begin{syntax}
%     \cs{str_aux_escape:NNNn} \meta{fn1} \meta{fn2} \meta{fn3} \Arg{token list}
%   \end{syntax}
%   The \meta{token list} is converted to a string, then read from
%   left to right, interpreting backslashes as escaping the next character.
%   Unescaped characters are fed to the function \meta{fn1},
%   and escaped characters are fed to the function \meta{fn2}
%   within an \texttt{x}-expansion context (typically those functions
%   perform some tests on their argument to decide how to output them).
%   The escape sequences |\a|, |\e|, |\f|, |\n|, |\r|, |\t| and |\x|
%   are recognized as described for \cs{str_input:Nn}, and those
%   are replaced by the corresponding character, then fed to
%   \meta{fn3}. The result is assigned globally to \cs{g_str_result_tl}.
% \end{function}
%
% \section{Possibilities}
%
% \begin{itemize}
% \item More encodings (see Heiko's \pkg{stringenc}).
%   In particular, what is needed for pdf: \textsc{utf-16}?
% \item \cs{str_if_head_eq:nN} alias of \cs{tl_if_head_eq_charcode:nN}
% \item \cs{str_if_numeric/decimal/integer:n}, perhaps in \pkg{l3fp}?
% \item Should \cs{str_item:Nn} be \cs{str_char:Nn}?
% \end{itemize}
% Some functionalities of \pkg{stringstrings} and \pkg{xstring} as well.
%
% \end{documentation}
%
% \begin{implementation}
%
% \section{\pkg{l3str} implementation}
%
%    \begin{macrocode}
%<*initex|package>
%    \end{macrocode}
%
%    \begin{macrocode}
\ProvidesExplPackage
  {\ExplFileName}{\ExplFileDate}{\ExplFileVersion}{\ExplFileDescription}
%    \end{macrocode}
%
% Those string-related functions are defined in \pkg{l3kernel}.
% \begin{itemize}
%   \item \cs{str_if_eq:nn}[pTF] and variants,
%   \item \cs{str_if_eq_return:on},
%   \item \cs{tl_to_str:n}, \cs{tl_to_str:N}, \cs{tl_to_str:c},
%   \item \cs{token_to_str:N}, \cs{cs_to_str:N}
%   \item \cs{str_head:n}, \cs{str_head_aux:w}, (copied here)
%   \item \cs{str_tail:n}, \cs{str_tail_aux:w}, (copied here)
%   \item \cs{str_length_skip_spaces} (deprecated)
%   \item \cs{str_length_loop:NNNNNNNNN} (unchanged)
% \end{itemize}
%
% \subsection{General functions}
%
% \begin{macro}[EXP,aux]{\use_i:nnnnnnnn}
%   A function which may already be defined elsewhere.
%    \begin{macrocode}
\cs_if_exist:NF \use_i:nnnnnnnn
  { \cs_new:Npn \use_i:nnnnnnnn #1#2#3#4#5#6#7#8 {#1} }
%    \end{macrocode}
% \end{macro}
%
% \begin{variable}
%   {
%     \c_forty_eight, \c_fifty_eight, \c_sixty_five, \c_ninety_one,
%     \c_ninety_seven, \c_one_hundred_twenty_three,
%     \c_one_hundred_twenty_seven
%   }
%   We declare here some integer values which delimit ranges of
%   ASCII characters of various types. This is mostly used in
%   \pkg{l3regex}.
%    \begin{macrocode}
\int_const:Nn \c_forty_eight  { 48 }
\int_const:Nn \c_fifty_eight  { 58 }
\int_const:Nn \c_sixty_five   { 65 }
\int_const:Nn \c_ninety_one   { 91 }
\int_const:Nn \c_ninety_seven { 97 }
\int_const:Nn \c_one_hundred_twenty_three { 123 }
\int_const:Nn \c_one_hundred_twenty_seven { 127 }
%    \end{macrocode}
% \end{variable}
%
% \begin{variable}{\c_max_char_int}
%   The maximum character code depends on the engine.
%    \begin{macrocode}
\pdftex_if_engine:TF
  { \int_const:Nn \c_max_char_int { 255 } }
  { \int_const:Nn \c_max_char_int { 1114111 } }
%    \end{macrocode}
% \end{macro}
%
% \begin{variable}{\c_str_replacement_char_int}
%   When converting, invalid bytes are replaced by the Unicode
%   replacement character \textsc{u-fffd}.
%    \begin{macrocode}
\int_const:Nn \c_str_replacement_char_int { "FFFD }
%    \end{macrocode}
% \end{variable}
%
% \begin{macro}
%   {
%     \str_set:Nn, \str_set:Nx,
%     \str_set:cn, \str_set:cx,
%     \str_gset:Nn, \str_gset:Nx,
%     \str_gset:cn, \str_gset:cx,
%     \str_const:Nn, \str_const:Nx,
%     \str_const:cn, \str_const:cx,
%     \str_put_left:Nn, \str_put_left:Nx,
%     \str_put_left:cn, \str_put_left:cx,
%     \str_gput_left:Nn, \str_gput_left:Nx,
%     \str_gput_left:cn, \str_gput_left:cx,
%     \str_put_right:Nn, \str_put_right:Nx,
%     \str_put_right:cn, \str_put_right:cx,
%     \str_gput_right:Nn, \str_gput_right:Nx,
%     \str_gput_right:cn, \str_gput_right:cx,
%   }
%   Simply convert the token list inputs to \meta{strings}.
%    \begin{macrocode}
\group_begin:
  \cs_set_protected_nopar:Npn \str_tmp:w #1
    {
      \cs_new_protected:cpx { str_ #1 :Nn } ##1##2
        { \exp_not:c { tl_ #1 :Nx } ##1 { \exp_not:N \tl_to_str:n {##2} } }
      \exp_args:Nc \cs_generate_variant:Nn { str_ #1 :Nn } { Nx , cn , cx }
    }
  \str_tmp:w { set }
  \str_tmp:w { gset }
  \str_tmp:w { const }
  \str_tmp:w { put_left }
  \str_tmp:w { gput_left }
  \str_tmp:w { put_right }
  \str_tmp:w { gput_right }
\group_end:
%    \end{macrocode}
% \end{macro}
%
% \subsection{Variables and constants}
%
% \begin{macro}{\str_tmp:w}
% \begin{variable}{\g_str_tmpa_tl}
%   Internal scratch space for some functions.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_tmp:w { }
\tl_new:N \g_str_tmpa_tl
%    \end{macrocode}
% \end{variable}
% \end{macro}
%
% \begin{variable}{\g_str_result_tl}
%   The \cs{g_str_result_tl} variable is used to hold the result
%   of various internal string operations which are typically
%   performed in a group. The variable is global so that it remains
%   defined outside the group, to be assigned to a user provided variable.
%    \begin{macrocode}
\tl_new:N \g_str_result_tl
%    \end{macrocode}
% \end{variable}
%
% \begin{variable}{\l_str_char_int}
%   When converting from various forms to characters,
%   \cs{l_str_char_int} is the character code of the
%   character which should be created.
%    \begin{macrocode}
\int_new:N \l_str_char_int
%    \end{macrocode}
% \end{variable}
%
% \begin{variable}
%   {
%     \c_backslash_str,
%     \c_lbrace_str,
%     \c_rbrace_str,
%     \c_hash_str,
%     \c_tilde_str,
%     \c_percent_str
%   }
%   For all of those strings, \cs{cs_to_str:N} produce characters
%   with the correct category code.
%    \begin{macrocode}
\tl_const:Nx \c_backslash_str { \cs_to_str:N \\ }
\tl_const:Nx \c_lbrace_str    { \cs_to_str:N \{ }
\tl_const:Nx \c_rbrace_str    { \cs_to_str:N \} }
\tl_const:Nx \c_hash_str      { \cs_to_str:N \# }
\tl_const:Nx \c_tilde_str     { \cs_to_str:N \~ }
\tl_const:Nx \c_percent_str   { \cs_to_str:N \% }
%    \end{macrocode}
% \end{variable}
%
% \subsection{Internal functions}
%
% \subsubsection{Escaping spaces}
%
% \begin{macro}[EXP]{\tl_to_other_str:N, \tl_to_other_str:n}
% \begin{macro}[EXP,aux]{\tl_to_other_str_loop:w, \tl_to_other_str_end:w}
%   Replaces all spaces by \enquote{other} spaces, after converting
%   the token list to a string via \cs{tl_to_str:n}.
%    \begin{macrocode}
\group_begin:
\char_set_lccode:nn { `\* } { `\  }
\char_set_lccode:nn { `\A } { `\A }
\tl_to_lowercase:n
  {
    \group_end:
    \cs_new:Npn \tl_to_other_str:n #1
      {
        \exp_after:wN \tl_to_other_str_loop:w \tl_to_str:n {#1} ~ %
        A ~ A ~ A ~ A ~ A ~ A ~ A ~ A ~ \q_mark \q_stop
      }
    \cs_new_nopar:Npn \tl_to_other_str_loop:w
      #1 ~ #2 ~ #3 ~ #4 ~ #5 ~ #6 ~ #7 ~ #8 ~ #9 \q_stop
      {
        \if_meaning:w A #8
          \tl_to_other_str_end:w
        \fi:
        \tl_to_other_str_loop:w
        #9 #1 * #2 * #3 * #4 * #5 * #6 * #7 * #8 * \q_stop
      }
    \cs_new_nopar:Npn \tl_to_other_str_end:w \fi: #1 \q_mark #2 * A #3 \q_stop
      { \fi: #2 }
  }
\cs_new_nopar:Npn \tl_to_other_str:N { \exp_args:No \tl_to_other_str:n }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP]{\str_sanitize_args:Nn, \str_sanitize_args:Nnn}
%   Here, \texttt{f}-expansion does not lose leading spaces,
%   since they have catcode \enquote{other} after \cs{str_sanitize:n}.
%    \begin{macrocode}
\cs_new:Npn \str_sanitize_args:Nn #1#2
  { \exp_args:Nf #1 { \tl_to_other_str:n {#2} } }
\cs_new:Npn \str_sanitize_args:Nnn #1#2#3
  {
    \exp_args:Nff #1
      { \tl_to_other_str:n {#2} }
      { \tl_to_other_str:n {#3} }
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[int]{\str_aux_gset_other:Nn}
% \begin{macro}[aux,EXP]{\str_aux_gset_other_loop:w}
% \begin{macro}[aux,EXP]{\str_aux_gset_other_end:w}
%    \begin{macrocode}
\group_begin:
\char_set_lccode:nn { `\* } { `\  }
\char_set_lccode:nn { `\A } { `\A }
\tl_to_lowercase:n
  {
    \group_end:
    \cs_new_protected:Npn \str_aux_gset_other:Nn #1#2
      {
        \tl_gset:Nx #1
          {
            \exp_after:wN \str_aux_gset_other_loop:w \tl_to_str:n {#2} ~ %
            A ~ A ~ A ~ A ~ A ~ A ~ A ~ A ~ A ~ \q_mark \q_stop
          }
      }
    \cs_new_nopar:Npn \str_aux_gset_other_loop:w
      #1 ~ #2 ~ #3 ~ #4 ~ #5 ~ #6 ~ #7 ~ #8 ~ #9 ~
      {
        \if_meaning:w A #9
          \str_aux_gset_other_end:w
        \fi:
        #1 * #2 * #3 * #4 * #5 * #6 * #7 * #8 * #9
        \str_aux_gset_other_loop:w *
      }
    \cs_new_nopar:Npn \str_aux_gset_other_end:w \fi: #1 * A #2 \q_stop
      { \fi: #1 }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsubsection{Mapping}
%
% \begin{macro}[rEXP,int]{\str_map_tokens:nn}
% \begin{macro}[rEXP,int]{\str_map_tokens:Nn}
% \begin{macro}[rEXP,aux]{\str_map_tokens_aux:nn}
% \begin{macro}[rEXP,aux]{\str_map_tokens_loop:nw}
% \begin{macro}[rEXP,aux]{\str_map_tokens_loop:nN}
% \begin{macro}[rEXP,int]{\str_map_break_do:n}
%   We simply need to be careful with spaces.
%   Spaces are fed to the mapped tokens with
%   category code $12$, not $10$.
%    \begin{macrocode}
\cs_new_nopar:Npn \str_map_tokens:Nn
  { \exp_args:No \str_map_tokens:nn }
\cs_new:Npn \str_map_tokens:nn #1
  { \exp_args:No \str_map_tokens_aux:nn { \tl_to_str:n {#1} } }
\cs_new:Npn \str_map_tokens_aux:nn #1#2
  {
    \str_map_tokens_loop:nw {#2} #1
      { ? \use_none_delimit_by_q_recursion_stop:w }
      ?~ ?~ ?~ ?~ ?~ ?~ ?~ ?~ \q_recursion_stop
  }
\group_begin:
  \char_set_lccode:nn { `* } { `\ }
  \tl_to_lowercase:n
    {
      \group_end:
      \cs_new:Npn \str_map_tokens_loop:nw #1 #2~ #3~ #4~ #5~ #6~ #7~ #8~ #9~
        {
          \str_map_tokens_loop:nN {#1} #2* #3* #4* #5* #6* #7* #8* #9*
            { ? \use_none_delimit_by_q_stop:w } \q_stop
          \str_map_tokens_loop:nw {#1}
        }
    }
\cs_new:Npn \str_map_tokens_loop:nN #1#2
  {
    \use_none:n #2
    #1 #2
    \str_map_tokens_loop:nN {#1}
  }
\cs_new_eq:NN \str_map_break_do:n \use_i_delimit_by_q_recursion_stop:nw
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsection{Characters given by their position}
%
% \begin{macro}[EXP]{\str_length:N}
% \begin{macro}[EXP]{\str_length:n}
% \begin{macro}[EXP]{\str_length_ignore_spaces:n}
% \begin{macro}[EXP]{\str_length_unsafe:n}
% \begin{macro}[EXP,aux]{\str_length_aux:n,\str_length_loop:NNNNNNNNN}
%   The length of a string is found by first changing all spaces
%   to other spaces using \cs{tl_to_other_str:n}, then counting
%   characters $9$ at a time. When the end is reached, |#9|
%   has the form |X|\meta{digit}, the catcode test is true,
%   the digit gets added to the sum, and the loop is terminated
%   by \cs{use_none_delimit_by_q_stop:w}.
%    \begin{macrocode}
\cs_new_nopar:Npn \str_length:N { \exp_args:No \str_length:n }
\cs_new:Npn \str_length:n { \str_sanitize_args:Nn \str_length_unsafe:n }
\cs_new_nopar:Npn \str_length_unsafe:n #1
  { \str_length_aux:n { \str_length_loop:NNNNNNNNN #1 } }
\cs_new:Npn \str_length_ignore_spaces:n #1
  {
    \str_length_aux:n
      { \exp_after:wN \str_length_loop:NNNNNNNNN \tl_to_str:n {#1} }
  }
\cs_new:Npn \str_length_aux:n #1
  {
    \int_eval:n
      {
        #1
        { X \c_eight } { X \c_seven } { X \c_six   }
        { X \c_five  } { X \c_four  } { X \c_three }
        { X \c_two   } { X \c_one   } { X \c_zero  }
        \q_stop
      }
  }
\cs_set:Npn \str_length_loop:NNNNNNNNN #1#2#3#4#5#6#7#8#9
  {
    \if_catcode:w X #9
      \exp_after:wN \use_none_delimit_by_q_stop:w
    \fi:
    \c_nine + \str_length_loop:NNNNNNNNN
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP]{\str_head:N}
% \begin{macro}[EXP]{\str_head:n}
% \begin{macro}[EXP]{\str_head_ignore_spaces:n}
% \begin{macro}[EXP]{\str_head_unsafe:n}
% \begin{macro}[EXP,aux]{\str_head_aux:w}
%   The cases of \cs{str_head_ignore_spaces:n} and
%   \cs{str_head_unsafe:n} are mostly identical to
%   \cs{tl_head:n}.
%   As usual, \cs{str_head:N} expands its argument and hands it to
%   \cs{str_head:n}. To circumvent the fact that \TeX{} skips spaces
%   when grabbing undelimited macro parameters, \cs{str_head_aux:w}
%   takes an argument delimited by a space. If |#1| starts with a
%   non-space character, \cs{use_i_delimit_by_q_stop:nw} leaves that
%   in the input stream. On the other hand, if |#1| starts with a
%   space, the \cs{str_head_aux:w} takes an empty argument, and
%   the single (braced) space in the definition of \cs{str_head_aux:w}
%   makes its way to the output. Finally, for an empty argument,
%   the (braced) empty brace group in the definition of \cs{str_head:n}
%   gives an empty result after passing through
%   \cs{use_i_delimit_by_q_stop:nw}.
%    \begin{macrocode}
\cs_new_nopar:Npn \str_head:N { \exp_args:No \str_head:n }
\cs_set:Npn \str_head:n #1
  {
    \exp_after:wN \str_head_aux:w
    \tl_to_str:n {#1}
    { { } } ~ \q_stop
  }
\cs_set_nopar:Npn \str_head_aux:w #1 ~ %
  { \use_i_delimit_by_q_stop:nw #1 { ~ } }
\cs_new:Npn \str_head_ignore_spaces:n #1
  { \exp_after:wN \use_i_delimit_by_q_stop:nw \tl_to_str:n {#1} { } \q_stop }
\cs_new_nopar:Npn \str_head_unsafe:n #1
  { \use_i_delimit_by_q_stop:nw #1 { } \q_stop }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP]{\str_tail:N}
% \begin{macro}[EXP]{\str_tail:n}
% \begin{macro}[EXP]{\str_tail_ignore_spaces:n}
% \begin{macro}[EXP]{\str_tail_unsafe:n}
% \begin{macro}[EXP,aux]{\str_tail_aux:w}
% \begin{macro}[EXP,aux]{\str_tail_aux_ii:w}
%   As when fetching the head of a string, the cases
%   \enquote{\texttt{ignore_spaces:n}} and \enquote{\texttt{unsafe:n}}
%   are similar to \cs{tl_tail:n}.
%   The more commonly used \cs{str_tail:n} function is a little bit
%   more convoluted: hitting the front of the string with
%   \cs{reverse_if:N} \cs{if_charcode:w} \cs{scan_stop:}
%   removes the first character (which necessarily makes the test true,
%   since it cannot match \cs{scan_stop:}). The auxiliary function inserts
%   the required \cs{fi:} to close the conditional, and leaves the tail
%   of the string in the input string. The details are such that an empty
%   string has an empty tail.
%    \begin{macrocode}
\cs_new_nopar:Npn \str_tail:N { \exp_args:No \str_tail:n }
\cs_set:Npn \str_tail:n #1
  {
    \exp_after:wN \str_tail_aux:w
    \reverse_if:N \if_charcode:w
        \scan_stop: \tl_to_str:n {#1} X X \q_stop
  }
\cs_set_nopar:Npn \str_tail_aux:w #1 X #2 \q_stop { \fi: #1 }
\cs_new:Npn \str_tail_ignore_spaces:n #1
  {
    \exp_after:wN \str_tail_aux_ii:w
    \tl_to_str:n {#1} X { } X \q_stop
  }
\cs_new_nopar:Npn \str_tail_unsafe:n #1
  { \str_tail_aux_ii:w #1 X { } X \q_stop }
\cs_new_nopar:Npn \str_tail_aux_ii:w #1 #2 X #3 \q_stop { #2 }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP,int]{\str_skip_do:nn}
% \begin{macro}[EXP,aux]{\str_skip_aux:nnnnnnnnn}
% \begin{macro}[EXP,aux]{\str_skip_end:nn}
% \begin{macro}[EXP,aux]{\str_skip_end_ii:nwn}
%   Removes |max(#1,0)| characters then leaves |#2| in the input stream.
%   We remove characters $7$ at a time. When the number of characters
%   to remove is not a multiple of $7$, we need to remove less than
%   $7$ characters in the last step. This is done by inserting a number
%   of \texttt{X}, which are discarded as if they were part of the string.
%    \begin{macrocode}
\cs_new:Npn \str_skip_do:nn #1
  {
    \if_num:w \int_eval:w #1 > \c_seven
      \exp_after:wN \str_skip_aux:nnnnnnnnn
    \else:
      \exp_after:wN \str_skip_end:n
    \fi:
      {#1}
  }
\cs_new:Npn \str_skip_aux:nnnnnnnnn #1#2#3#4#5#6#7#8#9
  { \exp_args:Nf \str_skip_do:nn { \int_eval:n { #1 - \c_seven } } {#2} }
\cs_new:Npn \str_skip_end:n #1
  {
    \if_case:w \int_eval:w #1 \int_eval_end:
         \str_skip_end_ii:nwn { XXXXXXX }
    \or: \str_skip_end_ii:nwn { XXXXXX }
    \or: \str_skip_end_ii:nwn { XXXXX }
    \or: \str_skip_end_ii:nwn { XXXX }
    \or: \str_skip_end_ii:nwn { XXX }
    \or: \str_skip_end_ii:nwn { XX }
    \or: \str_skip_end_ii:nwn { X }
    \or: \str_skip_end_ii:nwn {  }
    \else: \str_skip_end_ii:nwn { XXXXXXX }
    \fi:
  }
\cs_new:Npn \str_skip_end_ii:nwn #1#2 \fi: #3
  { \fi: \use_i:nnnnnnnn {#3} #1 }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP,int]{\str_collect_do:nn}
% \begin{macro}[EXP,aux]{\str_collect_aux:n,\str_collect_aux:nnNNNNNNN}
% \begin{macro}[EXP,aux]
%   {
%     \str_collect_end:nn,
%     \str_collect_end_ii:nwn,
%     \str_collect_end_iii:nwNNNNNNN
%   }
%   Collects |max(#1,0)| characters, and feeds them as an argument to |#2|.
%   Again, we grab $7$ characters at a time. Instead of inserting
%   a string of \texttt{X} to fill in to a multiple of $7$, we insert
%   empty groups, so that they disappear in this context where arguments
%   are accumulated.
%    \begin{macrocode}
\cs_new:Npn \str_collect_do:nn #1#2
  { \str_collect_aux:n {#1} { \str_collect_end_iii:nwNNNNNNN {#2} } }
\cs_new:Npn \str_collect_aux:n #1
  {
    \int_compare:nNnTF {#1} > \c_seven
      { \str_collect_aux:nnNNNNNNN }
      { \str_collect_end:n }
      {#1}
  }
\cs_new:Npn \str_collect_aux:nnNNNNNNN #1#2 #3#4#5#6#7#8#9
  {
    \exp_args:Nf \str_collect_aux:n
      { \int_eval:n { #1 - \c_seven } }
      { #2 #3#4#5#6#7#8#9 }
  }
\cs_new:Npn \str_collect_end:n #1
  {
    \if_case:w \int_eval:w #1 \int_eval_end:
         \str_collect_end_ii:nwn { { } { } { } { } { } { } { } }
    \or: \str_collect_end_ii:nwn { { } { } { } { } { } { } }
    \or: \str_collect_end_ii:nwn { { } { } { } { } { } }
    \or: \str_collect_end_ii:nwn { { } { } { } { } }
    \or: \str_collect_end_ii:nwn { { } { } { } }
    \or: \str_collect_end_ii:nwn { { } { } }
    \or: \str_collect_end_ii:nwn { { } }
    \or: \str_collect_end_ii:nwn {  }
    \else: \str_collect_end_ii:nwn { { } { } { } { } { } { } { } }
    \fi:
  }
\cs_new:Npn \str_collect_end_ii:nwn #1#2 \fi: #3
  { \fi: #3 \q_stop #1 }
\cs_new:Npn \str_collect_end_iii:nwNNNNNNN #1 #2 \q_stop #3#4#5#6#7#8#9
  { #1 {#2#3#4#5#6#7#8#9} }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP]{\str_item:Nn}
% \begin{macro}[EXP]{\str_item:nn}
% \begin{macro}[EXP]{\str_item_ignore_spaces:nn}
% \begin{macro}[EXP]{\str_item_unsafe:nn}
% \begin{macro}[EXP,aux]{\str_item_aux:nn}
%   This is mostly shuffling arguments around to avoid measuring
%   the length of the string more than once, and make sure that
%   the parameters given to \cs{str_skip_do:nn} are necessarily
%   within the bounds of the length of the string.
%   The \cs{str_item_ignore_spaces:nn} function cheats a little bit
%   in that it doesn't hand to \cs{str_item_unsafe:nn} a truly
%   \enquote{safe} string. This is alright, as everything else
%   is done with undelimited arguments.
%    \begin{macrocode}
\cs_new_nopar:Npn \str_item:Nn { \exp_args:No \str_item:nn }
\cs_new:Npn \str_item:nn #1#2
  {
    \exp_args:Nf \tl_to_str:n
      { \str_sanitize_args:Nn \str_item_unsafe:nn {#1} {#2} }
  }
\cs_new:Npn \str_item_ignore_spaces:nn #1
  { \exp_args:No \str_item_unsafe:nn { \tl_to_str:n {#1} } }
\cs_new_nopar:Npn \str_item_unsafe:nn #1#2
  {
    \exp_args:Nff \str_item_aux:nn
      { \int_eval:n {#2} }
      { \str_length_unsafe:n {#1} }
      #1
    \q_stop
  }
\cs_new_nopar:Npn \str_item_aux:nn #1#2
  {
    \int_compare:nNnTF {#1} < \c_zero
      {
        \int_compare:nNnTF {#1} < {-#2}
          { \use_none_delimit_by_q_stop:w }
          {
            \str_skip_do:nn { #1 + #2 }
              { \use_i_delimit_by_q_stop:nw }
          }
      }
      {
        \int_compare:nNnTF {#1} < {#2}
          {
            \str_skip_do:nn {#1}
              { \use_i_delimit_by_q_stop:nw }
          }
          { \use_none_delimit_by_q_stop:w }
      }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP]{\str_substr:Nnn}
% \begin{macro}[EXP]{\str_substr:nnn}
% \begin{macro}[EXP]{\str_substr_ignore_spaces:nnn}
% \begin{macro}[EXP]{\str_substr_unsafe:nnn}
% \begin{macro}[EXP,aux]{\str_substr_aux:nnnw}
% \begin{macro}[EXP,aux]{\str_substr_aux_ii:nnw}
% \begin{macro}[EXP,aux]{\str_aux_eval_args:Nnnn}
% \begin{macro}[EXP,aux]{\str_aux_normalize_range:nn}
%   Sanitize the string, then limit the second and third arguments
%   to be at most the length of the string (this avoids needing
%   to check for the end of the string when grabbing characters).
%   Afterwards, skip characters, then keep some more, and finally
%   drop the end of the string.
%    \begin{macrocode}
\cs_new_nopar:Npn \str_substr:Nnn { \exp_args:No \str_substr:nnn }
\cs_new:Npn \str_substr:nnn #1#2#3
  {
    \exp_args:Nf \tl_to_str:n
      { \str_sanitize_args:Nn \str_substr_unsafe:nnn {#1} {#2} {#3} }
  }
\cs_new:Npn \str_substr_ignore_spaces:nnn #1
  { \exp_args:No \str_substr_unsafe:nnn { \tl_to_str:n {#1} } }
\cs_new:Npn \str_substr_unsafe:nnn #1#2#3
  {
    \str_aux_eval_args:Nnnn \str_substr_aux:nnnw
      { \str_length_unsafe:n {#1} }
      {#2}
      {#3}
      #1
    \q_stop
  }
\cs_new:Npn \str_substr_aux:nnnw #1#2#3
  {
    \exp_args:Nf \str_substr_aux_ii:nnw
      { \str_aux_normalize_range:nn {#2} {#1} }
      { \str_aux_normalize_range:nn {#3} {#1} }
  }
\cs_new:Npn \str_substr_aux_ii:nnw #1#2
  {
    \str_skip_do:nn {#1}
      {
        \exp_args:Nf \str_collect_do:nn
          { \int_eval:n { #2 - #1 } }
          { \use_i_delimit_by_q_stop:nw }
      }
  }
\cs_new:Npn \str_aux_eval_args:Nnnn #1#2#3#4
  {
    \exp_after:wN #1
    \exp_after:wN { \int_value:w \int_eval:w #2 \exp_after:wN }
    \exp_after:wN { \int_value:w \int_eval:w #3 \exp_after:wN }
    \exp_after:wN { \int_value:w \int_eval:w #4 }
  }
\cs_new:Npn \str_aux_normalize_range:nn #1#2
  {
    \int_eval:n
      {
        \if_num:w #1 < \c_zero
          \if_num:w #1 < - #2 \exp_stop_f:
            \c_zero
          \else:
            #1 + #2
          \fi:
        \else:
          \if_num:w #1 < #2 \exp_stop_f:
            #1
          \else:
            #2
          \fi:
        \fi:
      }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsection{String conditionals}
%
% \begin{macro}[EXP,pTF]{\str_if_eq:NN}
% \begin{macro}[EXP,pTF]{\str_if_eq:nn,\str_if_eq:xx}
%   The \texttt{nn} and \texttt{xx} variants are already
%   defined in \pkg{l3basics}.
%    \begin{macrocode}
\prg_new_conditional:Npnn \str_if_eq:NN #1#2 { p , TF , T , F }
  {
    \if_int_compare:w \pdftex_strcmp:D { \tl_to_str:N #1 } { \tl_to_str:N #2 }
      = \c_zero \prg_return_true: \else: \prg_return_false: \fi:
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
%^^A treat spaces separately, or make that internal and faster.
% \begin{macro}[EXP,pTF]{\str_if_contains_char:NN}
% \begin{macro}[EXP,pTF]{\str_if_contains_char:nN}
% \begin{macro}[EXP,aux]{\str_if_contains_char_aux:NN}
% \begin{macro}[EXP,aux]{\str_if_contains_char_end:w}
%   Loop over the characters of the string, comparing character codes.
%   We allow |#2| to be a single-character control sequence, hence the
%   use of \cs{int_compare:nNnT} rather than \cs{token_if_eq_charcode:NNT}.
%   The loop is broken if character codes match. Otherwise we return
%   \enquote{false}.
%    \begin{macrocode}
\prg_new_conditional:Npnn \str_if_contains_char:NN #1#2 { p , T , F , TF }
  {
    \str_map_tokens:Nn #1 { \str_if_contains_char_aux:NN #2 }
    \prg_return_false:
  }
\prg_new_conditional:Npnn \str_if_contains_char:nN #1#2 { p , T , F , TF }
  {
    \str_map_tokens:nn {#1} { \str_if_contains_char_aux:NN #2 }
    \prg_return_false:
  }
\cs_new_nopar:Npn \str_if_contains_char_aux:NN #1#2
  {
    \if_num:w `#1 = `#2 \exp_stop_f:
      \str_if_contains_char_end:w
    \fi:
  }
\cs_new_nopar:Npn \str_if_contains_char_end:w \fi: #1 \prg_return_false:
  { \fi: \prg_return_true: }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[EXP,pTF]{\str_if_bytes:N}
% \begin{macro}[EXP,aux]{\str_if_bytes_aux:N}
% \begin{macro}[EXP,aux]{\str_if_bytes_aux:}
%   In the pdf\TeX{} engine, every character is a byte,
%   so there is nothing to check. In other engines, we
%   loop over the string, checking if every character
%   code is less than $256$.
%    \begin{macrocode}
\pdftex_if_engine:TF
  {
    \cs_new_eq:NN \str_if_bytes_p:N \c_true_bool
    \cs_new_eq:NN \str_if_bytes:NT  \use_ii:nn
    \cs_new_eq:NN \str_if_bytes:NF  \use_none:nn
    \cs_new_eq:NN \str_if_bytes:NTF \use_ii:nnn
  }
  {
    \prg_new_conditional:Npnn \str_if_bytes:N #1 { p , T , F , TF }
      {
        \exp_args:Nf \tl_map_function:nN
          { \tl_to_str:N #1 }
          \str_if_bytes_aux:N
        \prg_return_true:
      }
    \cs_new_nopar:Npn \str_if_bytes_aux:N #1
      {
        \if_num:w `#1 > \c_two_hundred_fifty_five
          \exp_after:wN \str_if_bytes_aux:
        \fi:
      }
    \cs_new_nopar:Npn \str_if_bytes_aux:
      { \tl_map_break:n { \prg_return_false: \use_none:n } }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsection{Conversions}
%
% \subsubsection{Internal conditionals}
%
% \begin{macro}[aux]{\str_aux_hexadecimal_test:NTF}
%   This test is used when reading hexadecimal digits, for the |\x| escape
%   sequence. It returns \meta{true} if the
%   token is a hexadecimal digit, and \meta{false} otherwise. It has the
%   additional side-effect of updating the value of
%   \cs{l_str_char_int} (number formed in base $16$ from the digits
%   read so far).
%^^A todo: speed tweaks?
%    \begin{macrocode}
\prg_new_protected_conditional:Npnn \str_aux_hexadecimal_test:N #1 { TF }
  {
    \tl_if_in:onTF { \tl_to_str:n { abcdef } } {#1}
      {
        \int_set:Nn \l_str_char_int
          { \c_sixteen * \l_str_char_int + `#1 - 87 }
        \prg_return_true:
      }
      {
        \if_num:w \c_fifteen < "1 \exp_not:N #1 \exp_stop_f:
          \int_set:Nn \l_str_char_int
            { \c_sixteen * \l_str_char_int + "#1 }
          \prg_return_true:
        \else:
          \prg_return_false:
        \fi:
      }
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[aux, rEXP]{\str_aux_octal_use:NTF}
%   \TeX{} dutifully detects octal digits for us: if |#1|
%   is an octal digit, then the right-hand side of the
%   comparison is |'1#1|, greater than $1$. Otherwise,
%   the right-hand side stops as |'1|, and the conditional
%   takes the \texttt{false} branch.
%    \begin{macrocode}
\prg_new_conditional:Npnn \str_aux_octal_use:N #1 { TF }
  {
    \if_num:w \c_one < '1 #1 \exp_stop_f:
      #1 \prg_return_true:
    \else:
      \prg_return_false:
    \fi:
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[aux, rEXP]{\str_aux_hexadecimal_use:NTF}
%   \TeX{} detects uppercase hexadecimal digits for us
%   (see \cs{str_aux_octal_use:NTF}, but not the
%   lowercase letters, which we need to detect and replace
%   by their uppercase counterpart.
%    \begin{macrocode}
\prg_new_conditional:Npnn \str_aux_hexadecimal_use:N #1 { TF }
  {
    \if_num:w \c_two < "1 #1 \exp_stop_f:
      #1 \prg_return_true:
    \else:
      \if_case:w \int_eval:w `#1 - `a \int_eval_end:
           A \prg_return_true:
      \or: B \prg_return_true:
      \or: C \prg_return_true:
      \or: D \prg_return_true:
      \or: E \prg_return_true:
      \or: F \prg_return_true:
      \else: \prg_return_false:
      \fi:
    \fi:
  }
%    \end{macrocode}
% \end{macro}
%
% \subsubsection{Producing one byte or character}
%
% \begin{variable}{\c_str_byte_0_tl}
% \begin{variable}{\c_str_byte_-1_tl}
%   For each integer $N$ in the range $[0,255]$, we create
%   a constant token list which holds three character tokens
%   with category code other: the character with character
%   code $N$, followed by the representation of $N$ as
%   two hexadecimal digits.
%   The value $-1$ is given a default token list which ensures
%   that later functions give an empty result for the input $-1$.
%    \begin{macrocode}
\group_begin:
  \char_set_catcode_other:n { \c_zero }
  \tl_gset:Nx \g_str_result_tl { \tl_to_str:n { 0123456789ABCDEF } }
  \tl_map_inline:Nn \g_str_result_tl
    { \char_set_lccode:nn {`#1} {`#1} }
  \tl_map_inline:Nn \g_str_result_tl
    {
      \tl_map_inline:Nn \g_str_result_tl
        {
          \char_set_lccode:nn { \c_zero } {"##1#1}
          \tl_to_lowercase:n
            {
              \tl_const:cx
                { c_str_byte_ \int_eval:n {"##1#1} _tl }
                { ^^@ ##1 #1 }
            }
        }
    }
\group_end:
\tl_const:cn { c_str_byte_-1_tl } { { } \use_none:n { } }
%    \end{macrocode}
% \end{variable}
% \end{variable}
%
% \begin{macro}[int, EXP]{\str_output_byte:n}
% \begin{macro}[aux, EXP]{\str_output_byte:w}
% \begin{macro}[int, EXP]{\str_output_hexadecimal:n}
% \begin{macro}[aux, EXP]{\str_output_hexadecimal:w}
% \begin{macro}[aux, EXP]{\str_output_end:}
%   For now, no error detection, we simply pick either
%   the byte or the hexadecimal representation of it
%   from the three-character token list corresponding
%   to the argument.
%   The value $-1$ produces an empty result.
%    \begin{macrocode}
\cs_new:Npn \str_output_byte:n #1
  { \str_output_byte:w #1 \str_output_end: }
\cs_new_nopar:Npn \str_output_byte:w
  {
    \exp_after:wN \exp_after:wN
    \exp_after:wN \use_i:nnn
    \cs:w c_str_byte_ \int_use:N \int_eval:w
  }
\cs_new:Npn \str_output_hexadecimal:n #1
  { \str_output_hexadecimal:w #1 \str_output_end: }
\cs_new_nopar:Npn \str_output_hexadecimal:w
  {
    \exp_after:wN \exp_after:wN
    \exp_after:wN \use_none:n
    \cs:w c_str_byte_ \int_use:N \int_eval:w
  }
\cs_new_nopar:Npn \str_output_end:
  { \int_eval_end: _tl \cs_end: }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsubsection{}%^^A here
%
% \begin{macro}{\str_aux_gmap_result:N}
% \begin{macro}[aux, rEXP]{\str_aux_gmap_result_loop:NN}
%
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_aux_gmap_result:N #1
  {
    \tl_gset:Nx \g_str_result_tl
      {
        \exp_after:wN \str_aux_gmap_result_loop:NN
        \exp_after:wN #1
          \g_str_result_tl { ? \prg_map_break: }
        \prg_break_point:n { }
      }
  }
\cs_new_nopar:Npn \str_aux_gmap_result_loop:NN #1#2
  {
    \use_none:n #2
    #1#2
    \str_aux_gmap_result_loop:NN #1
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}{\str_aux_gmap_internal_result:N}
% \begin{macro}[aux, rEXP]{\str_aux_gmap_internal_result_loop:Nw}
%
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_aux_gmap_internal_result:N #1
  {
    \tl_gset:Nx \g_str_result_tl
      {
        \exp_after:wN \str_aux_gmap_internal_result_loop:Nw
        \exp_after:wN #1
          \g_str_result_tl \q_stop \prg_map_break: ,
        \prg_break_point:n { }
      }
  }
\cs_new_nopar:Npn \str_aux_gmap_internal_result_loop:Nw #1#2,
  {
    \use_none_delimit_by_q_stop:w #2 \q_stop
    #1 {#2}
    \str_aux_gmap_internal_result_loop:Nw #1
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \subsubsection{Unescape user input}
%
% The code of this section is used both here for \cs{str_(g)input:Nn},
% and in the regular expression module to go through the regular expression
% once before actually parsing it. The goal in that case is to turn any
% character with a meaning in regular expressions (\texttt{*}, \texttt{?},
% \texttt{\{}, etc.) into a marker indicating that this was a special
% character,
% and replace any escaped character by the corresponding unescaped character,
% so that the \pkg{l3regex} code can avoid caring about escaping issues
% (those can become quite complex to handle in combination with ranges
% in character classes).
%
% The idea is to feed unescaped characters to one function,
% escaped characters to another, and feed |\a|, |\e|, |\f|,
% |\n|, |\r|, |\t| and |\x| converted to the appropriate
% character to a third function. Spaces are ignored unless
% escaped.
% For the \cs{str_(g)input:Nn} application, all the functions are simply
% \cs{token_to_str:N} (this ensures that spaces correctly get assigned
% category code $10$).
% For the \pkg{l3regex} applications, the functions do some further
% tests on the character they receive.
%
% \begin{macro}{\str_input:Nn,\str_ginput:Nn}
%   Simple wrappers around the internal \cs{str_aux_escape:NNNn}.
%    \begin{macrocode}
\cs_new_protected:Npn \str_input:Nn #1#2
  {
    \str_aux_escape:NNNn \token_to_str:N \token_to_str:N \token_to_str:N {#2}
    \tl_set_eq:NN #1 \g_str_result_tl
  }
\cs_new_protected:Npn \str_ginput:Nn #1#2
  {
    \str_aux_escape:NNNn \token_to_str:N \token_to_str:N \token_to_str:N {#2}
    \tl_gset_eq:NN #1 \g_str_result_tl
  }
%    \end{macrocode}
% \end{macro}
%
% \begin{macro}[int]{\str_aux_escape:NNNn}
% \begin{macro}[aux]{\str_aux_escape_unescaped:N}
% \begin{macro}[aux]{\str_aux_escape_escaped:N}
% \begin{macro}[aux]{\str_aux_escape_raw:N}
% \begin{macro}[aux]{\str_aux_escape_loop:N}
% \begin{macro}[aux]+\str_aux_escape_\:w+
%   Treat the argument as an \meta{escaped string},
%   and store the corresponding \meta{string} globally
%   in \cs{g_str_result_tl}.
%    \begin{macrocode}
\cs_new_eq:NN \str_aux_escape_unescaped:N \use:n
\cs_new_eq:NN \str_aux_escape_escaped:N   \use:n
\cs_new_eq:NN \str_aux_escape_raw:N       \use:n
\cs_new_protected:Npn \str_aux_escape:NNNn #1#2#3#4
  {
    \group_begin:
      \cs_set_nopar:Npn \str_aux_escape_unescaped:N { #1 }
      \cs_set_nopar:Npn \str_aux_escape_escaped:N { #2 }
      \cs_set_nopar:Npn \str_aux_escape_raw:N { #3 }
      \int_set:Nn \tex_escapechar:D { 92 }
      \str_aux_gset_other:Nn \g_str_result_tl {#4}
      \tl_gset:Nx \g_str_result_tl
        {
          \exp_after:wN \str_aux_escape_loop:N \g_str_result_tl
          \q_recursion_tail \q_recursion_stop
        }
    \group_end:
  }
\cs_new_nopar:Npn \str_aux_escape_loop:N #1
  {
    \cs_if_exist_use:cF { str_aux_escape_\token_to_str:N #1:w }
      { \str_aux_escape_unescaped:N #1 }
    \str_aux_escape_loop:N
  }
\cs_new_nopar:cpn { str_aux_escape_ \c_backslash_str :w }
    \str_aux_escape_loop:N #1
  {
    \cs_if_exist_use:cF { str_aux_escape_/\token_to_str:N #1:w }
      { \str_aux_escape_escaped:N #1 }
    \str_aux_escape_loop:N
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[aux]+\str_aux_escape_\q_recursion_tail:w+
% \begin{macro}[aux]+\str_aux_escape_/\q_recursion_tail:w+
% \begin{macro}[aux]+\str_aux_escape_ :w+
% \begin{macro}[aux]
%   {
%     \str_aux_escape_/a:w, \str_aux_escape_/e:w, \str_aux_escape_/f:w,
%     \str_aux_escape_/n:w, \str_aux_escape_/r:w, \str_aux_escape_/t:w
%   }
%   The loop is ended upon seeing \cs{q_recursion_tail}.
%   Spaces are ignored, and |\a|, |\e|, |\f|, |\n|, |\r|, |\t| take
%   their meaning here.
%    \begin{macrocode}
\cs_new_eq:cN
  { str_aux_escape_ \c_backslash_str q_recursion_tail :w }
  \use_none_delimit_by_q_recursion_stop:w
\cs_new_eq:cN
  { str_aux_escape_ / \c_backslash_str q_recursion_tail :w }
  \use_none_delimit_by_q_recursion_stop:w
\cs_new_nopar:cpn { str_aux_escape_~:w } { }
\cs_new_nopar:cpx { str_aux_escape_/a:w }
  { \exp_not:N \str_aux_escape_raw:N \iow_char:N \^^G }
\cs_new_nopar:cpx { str_aux_escape_/t:w }
  { \exp_not:N \str_aux_escape_raw:N \iow_char:N \^^I }
\cs_new_nopar:cpx { str_aux_escape_/n:w }
  { \exp_not:N \str_aux_escape_raw:N \iow_char:N \^^J }
\cs_new_nopar:cpx { str_aux_escape_/f:w }
  { \exp_not:N \str_aux_escape_raw:N \iow_char:N \^^L }
\cs_new_nopar:cpx { str_aux_escape_/r:w }
  { \exp_not:N \str_aux_escape_raw:N \iow_char:N \^^M }
\cs_new_nopar:cpx { str_aux_escape_/e:w }
  { \exp_not:N \str_aux_escape_raw:N \iow_char:N \^^[ }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[aux]{\str_aux_escape_/x:w}
% \begin{macro}[aux]{\str_aux_escape_x_test:N}
% \begin{macro}[aux]{\str_aux_escape_x_unbraced_i:N}
% \begin{macro}[aux]{\str_aux_escape_x_unbraced_ii:N}
% \begin{macro}[aux]{\str_aux_escape_x_braced_loop:N}
% \begin{macro}[aux]{\str_aux_escape_x_braced_end:N}
% \begin{macro}[aux]{\str_aux_escape_x_end:}
%   When |\x| is encountered, interrupt the assignment,
%   and distinguish the cases of a braced or unbraced syntax.
%   In the braced case, collect arbitrarily many hexadecimal digits,
%   building the number in \cs{l_str_char_int} (this is a side effect
%   of \cs{str_aux_hexadecimal_test:NTF}), and check that
%   the run of digits was interrupted by a closing brace.
%   In the unbraced case, collect up to two hexadecimal digits,
%   possibly less, building the character number in \cs{l_str_char_int}.
%   In both cases, once all digits have been collected, use
%   the \TeX{} primitive \tn{lowercase} to produce that character,
%   and use a \cs{if_false:} trick to restart the assignment.
%    \begin{macrocode}
\cs_new_nopar:cpn { str_aux_escape_/x:w } \str_aux_escape_loop:N
  {
    \if_false: { \fi: }
    \int_zero:N \l_str_char_int
    \str_aux_escape_x_test:N
  }
\cs_new_protected_nopar:Npx \str_aux_escape_x_test:N #1
  {
    \exp_not:N \token_if_eq_charcode:NNTF \c_space_token #1
      { \exp_not:N \str_aux_escape_x_test:N }
      {
        \exp_not:N \token_if_eq_charcode:NNTF \c_lbrace_str #1
          { \exp_not:N \str_aux_escape_x_braced_loop:N }
          { \exp_not:N \str_aux_escape_x_unbraced_i:N #1 }
      }
  }
\cs_new_protected_nopar:Npn \str_aux_escape_x_unbraced_i:N #1
  {
    \str_aux_hexadecimal_test:NTF #1
      { \str_aux_escape_x_unbraced_ii:N }
      { \str_aux_escape_x_end: #1 }
  }
\cs_new_protected_nopar:Npn \str_aux_escape_x_unbraced_ii:N #1
  {
    \token_if_eq_charcode:NNTF \c_space_token #1
      { \str_aux_escape_x_unbraced_ii:N }
      {
        \str_aux_hexadecimal_test:NTF #1
          { \str_aux_escape_x_end: }
          { \str_aux_escape_x_end: #1 }
      }
  }
\cs_new_protected_nopar:Npn \str_aux_escape_x_braced_loop:N #1
  {
    \token_if_eq_charcode:NNTF \c_space_token #1
      { \str_aux_escape_x_braced_loop:N }
      {
        \str_aux_hexadecimal_test:NTF #1
          { \str_aux_escape_x_braced_loop:N }
          { \str_aux_escape_x_braced_end:N #1 }
      }
  }
\cs_new_protected_nopar:Npx \str_aux_escape_x_braced_end:N #1
  {
    \exp_not:N \token_if_eq_charcode:NNTF \c_rbrace_str #1
      { \exp_not:N \str_aux_escape_x_end: }
      {
        \msg_kernel_error:nn { str } { x-missing-brace }
        \exp_not:N \str_aux_escape_x_end: #1
      }
  }
\group_begin:
  \char_set_catcode_other:N \^^@
  \cs_new_protected_nopar:Npn \str_aux_escape_x_end:
    {
      \tex_lccode:D \c_zero \l_str_char_int
      \tl_to_lowercase:n
        {
          \tl_gput_right:Nx \g_str_result_tl
            { \if_false: } \fi:
            \str_aux_escape_raw:N ^^@
            \str_aux_escape_loop:N
        }
    }
\group_end:
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsubsection{Framework for encoding conversions}
%
% Most functions in this module expect to be working with
% \enquote{native} strings. Strings can also be stored as
% bytes, in one of many encodings, for instance \textsc{utf8}.
% The bytes themselves can be expressed as character
% tokens with the relevant character code, or as pairs
% of hexadecimal digits, \emph{etc.} The questions of going
% from arbitrary characters to bytes, and from bytes to \TeX{}
% tokens are mostly independent.
%
% Conversions are done in four steps:
% \begin{itemize}
% \item \enquote{input} produces a string of bytes;
% \item \enquote{from} interprets the byte string in the old encoding,
%   and converts it to a comma-list, each character becoming
%   \enquote{\ttfamily \meta{character code},};
% \item \enquote{to} encodes the internal comma list as a byte string
%   in the new encoding;
% \item \enquote{output} escapes bytes as requested.
% \end{itemize}
% The process is modified in case one of the encoding is
% \texttt{internal} or \texttt{native}: then the input or
% output step is ignored.
%
% \begin{macro}{\str_set_convert:Nnnn, \str_gset_convert:Nnnn}
% \begin{macro}[aux]{\str_convert_aux_i:NNnnn}
% \begin{macro}[aux]{\str_convert_aux_ii:wwwNnn}
% \begin{macro}[aux, rEXP]{\str_convert_aux_iii:nn}
% \begin{macro}[aux]{\str_convert_aux_iv:NNnnnnNN}
%   The input string is stored in \cs{g_str_result_tl},
%   then we call the various conversion functions, which all
%   act on \cs{g_str_result_tl}. The arguments |#3| and |#4|
%   of the \texttt{aux_i} function are split into their
%   \meta{encoding} and \meta{escaping} parts by \texttt{aux_ii}.
%   The conversion function names are built by \texttt{aux_iii},
%   which first tries to use the name as supplied by the user,
%   then filters it with \cs{str_aux_lowercase_alphanum:n}.
%   Once this is done, \texttt{aux_iv} does the main work:
%   \begin{itemize}
%   \item |#1| and |#2| are the conversion functions;
%   \item |#3| and |#4| are the encoding and escaping as given by the user;
%   \item |#5| and |#6| are either \texttt{from} and \texttt{input},
%     or \texttt{to} and \texttt{output};
%   \item |#7| and |#8| are \cs{use_none:n} and \cs{use:n} in some order.
%   \end{itemize}
%   The order of arguments is such that |#1|, |#3|, |#5| pertain
%   to the encoding, and |#2|, |#4|, |#6| to the escaping.
%   If the encoding function |#1| is unknown, it is permanently
%   set equal to the \texttt{native} encoding function
%   after raising an error once. Since filtering the user input
%   is expensive, we avoid doing it more than once on a given string
%   by defining the conversion functions to be equal to what
%   \texttt{aux_iii} had supplied (often, those assignments will
%   do nothing).
%   Then, |#7| and |#8| come into play: in the input--from phase,
%   the encoding transformation |#1| happens after the escaping,
%   while the to--output phase has the opposite order.
%   In case the encoding function corresponds to the native encoding,
%   we ignore the escaping, warning the user if he specified an escaping.
%   Otherwise, use the escaping function, catching the undefined case.
%    \begin{macrocode}
\cs_new_protected:Npn \str_set_convert:Nnnn
  { \str_convert_aux_i:NNnnn \str_set:Nx }
\cs_new_protected:Npn \str_gset_convert:Nnnn
  { \str_convert_aux_i:NNnnn \str_gset:Nx }
\cs_new_protected:Npn \str_convert_aux_i:NNnnn #1#2#3#4#5
  {
    \group_begin:
      \str_aux_gset_other:Nn \g_str_result_tl {#5}

      \exp_after:wN \str_convert_aux_ii:wwwNnn
        \tl_to_str:n {#3} /// \q_stop
        \str_convert_aux_iv:NNnnnnNN { from } { input }
        \use_none:n \use:n

      \exp_after:wN \str_convert_aux_ii:wwwNnn
        \tl_to_str:n {#4} /// \q_stop
        \str_convert_aux_iv:NNnnnnNN { to } { output }
        \use:n \use_none:n

    \group_end:
    #1 #2 \g_str_result_tl
  }
\cs_new_protected:Npn \str_convert_aux_ii:wwwNnn #1 / #2 // #3 \q_stop #4#5#6
  {
    \exp_args:Ncc #4
      { \str_convert_aux_iii:nn {#5} {#1} }
      { \str_convert_aux_iii:nn {#6} {#2} }
      {#1} {#2} {#5} {#6}
  }
\cs_new:Npn \str_convert_aux_iii:nn #1#2
  {
    str_convert_#1_
    \exp_args:Nc \cs_if_exist:NTF { str_convert_#1_#2: }
      { #2 : }
      { \str_aux_lowercase_alphanum:n {#2} : }
  }
\cs_new_protected:Npn \str_convert_aux_iv:NNnnnnNN #1#2#3#4#5#6#7#8
  {
    \cs_if_exist:NF #1
      {
        \msg_kernel_error:nnx { str } { unknown-#5 } {#3}
        \cs_gset_eq:Nc #1 { str_convert_#5_native: }
      }
    \cs_gset_eq:cN { str_convert_#5_#3: } #1
    \cs_gset_eq:cN { str_convert_#6_#4: } #2
    #7#1
    \cs_if_eq:cNTF { str_convert_#5_native: } #1
      {
        \tl_if_empty:nF {#4}
          { \msg_kernel_error:nnx { str } { native-ignore-#6 } {#4} }
      }
      {
        \cs_if_exist_use:NF #2
          {
            \msg_kernel_error:nnx { str } { unknown-#6 } {#4}
            \use:c { str_convert_#6_: }
          }
      }
    #8#1
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int, rEXP]{\str_aux_lowercase_alphanum:n}
% \begin{macro}[aux, rEXP]{\str_aux_lowercase_alphanum_loop:N}
%   This function keeps only letters and digits, with upper case
%   letters converted to lower case.
%    \begin{macrocode}
\cs_new:Npn \str_aux_lowercase_alphanum:n #1
  {
    \exp_after:wN \str_aux_lowercase_alphanum_loop:N
      \tl_to_str:n {#1} { ? \prg_map_break: }
    \prg_break_point:n { }
  }
\cs_new:Npn \str_aux_lowercase_alphanum_loop:N #1
  {
    \use_none:n #1
    \if_num:w `#1 < \c_ninety_one
      \if_num:w `#1 < \c_sixty_five
        \if_num:w \c_one < 1#1 \exp_stop_f:
          #1
        \fi:
      \else:
        \str_output_byte:n { `#1 + \c_thirty_two }
      \fi:
    \else:
      \if_num:w `#1 < \c_one_hundred_twenty_three
        \if_num:w `#1 < \c_ninety_seven
        \else:
          #1
        \fi:
      \fi:
    \fi:
    \str_aux_lowercase_alphanum_loop:N
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_from_internal:}
% \begin{macro}[int]{\str_convert_to_internal:}
%   Converting from the internal format to itself is
%   of course trivial.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_from_internal: { }
\cs_new_protected_nopar:Npn \str_convert_to_internal:   { }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \subsubsection{From input to bytes}
%
% Strings of bytes may need to be stored in auxiliary files
% in \enquote{safe} formats. We implement the conversion
% methods from those safe formats to bytes, and back.
% Several of those encodings are defined by the pdf file format.
%
% The following input methods are defined:
% \begin{itemize}
% \item \texttt{bytes} (default), non-bytes are filtered out,
%   and bytes are left untouched;
% \item \texttt{hex} or \texttt{hexadecimal},
%   as per the pdf\TeX{} primitive \tn{pdfescapehex}
% \item \texttt{name}, as per the pdf\TeX{} primitive \tn{pdfescapename}
% \item \texttt{string}, as per the pdf\TeX{} primitive \tn{pdfescapestring}
% \item \texttt{url} or \texttt{percent}, as per the percent encoding of urls.
% \end{itemize}
%^^A todo: in pdfTeX, use the \tn{pdfescape...}
%
% \begin{macro}[int, rEXP]{\str_filter_bytes:n}
% \begin{macro}[aux, rEXP]{\str_filter_bytes_aux:N}
%   In the case of pdf\TeX{}, every character is a byte.
%   For Unicode-aware engines, test the character code.
%   Spaces have already been given the correct category
%   code.
%    \begin{macrocode}
\pdftex_if_engine:TF
  { \cs_new_eq:NN \str_filter_bytes:n \use:n }
  {
    \cs_new_nopar:Npn \str_filter_bytes:n #1
      {
        \str_filter_bytes_aux:N #1
          { ? \prg_map_break: }
        \prg_break_point:n { }
      }
    \cs_new_nopar:Npn \str_filter_bytes_aux:N #1
      {
        \use_none:n #1
        \if_num:w `#1 < 256 \exp_stop_f: #1 \fi:
        \str_filter_bytes_aux:N
      }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_input_:}
% \begin{macro}[int]{\str_convert_input_bytes:}
%   The simplest input method simply removes non-bytes
%   from \cs{g_str_result_tl}.
%    \begin{macrocode}
\pdftex_if_engine:TF
  { \cs_new_protected_nopar:Npn \str_convert_input_: { } }
  {
    \cs_new_protected_nopar:Npn \str_convert_input_:
      {
        \tl_gset:Nx \g_str_result_tl
          { \exp_args:No \str_filter_bytes:n \g_str_result_tl }
      }
  }
\cs_new_eq:NN \str_convert_input_bytes: \str_convert_input_:
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_input_hex:}
% \begin{macro}[int]{\str_convert_input_hexadecimal:}
% \begin{macro}[aux, rEXP]{\str_convert_input_hex_aux:N}
% \begin{macro}[aux, rEXP]{\str_convert_input_hex_aux_ii:N}
%   Take chars two by two, and interpret  each pair as
%   the hexadecimal code for a byte. Anything else than
%   hexadecimal digits is ignored.
%   A string which contains an odd number of hexadecimal
%   digits gets |0| appended to it: this is equivalent
%   to appending a |0| in all cases, and dropping it if
%   it is alone.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_input_hex:
  {
    \tl_gset:Nx \g_str_result_tl
      {
        \str_output_byte:w "
          \exp_after:wN \str_convert_input_hex_aux:N
          \g_str_result_tl 0 { ? 0 - \c_one \prg_map_break: }
        \prg_break_point:n { \str_output_end: }
      }
  }
\cs_new_nopar:Npn \str_convert_input_hex_aux:N #1
  {
    \use_none:n #1
    \str_aux_hexadecimal_use:NTF #1
      \str_convert_input_hex_aux_ii:N
      \str_convert_input_hex_aux:N
  }
\cs_new_nopar:Npn \str_convert_input_hex_aux_ii:N #1
  {
    \use_none:n #1
    \str_aux_hexadecimal_use:NTF #1
      {
        \str_output_end:
        \str_output_byte:w " \str_convert_input_hex_aux:N
      }
      \str_convert_input_hex_aux_ii:N
  }
\cs_new_eq:NN \str_convert_input_hexadecimal: \str_convert_input_hex:
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_input_name:}
% \begin{macro}[aux, rEXP]{\str_convert_input_name_aux:wNN}
% \begin{macro}[int]{\str_convert_input_url:}
% \begin{macro}[int]{\str_convert_input_percent:}
% \begin{macro}[aux, rEXP]{\str_convert_input_url_aux:wNN}
%   The \cs{str_convert_input_name:} function replaces each
%   occurrence of |#| followed by two hexadecimal digits
%   in \cs{g_str_result_tl} by the corresponding byte.
%   The \texttt{url} function is identical, with escape
%   character |%| instead of |#|. Thus we define the two
%   together. The arguments of \cs{str_tmp:w} are the character
%   code of |#| or |%| in hexadecimal, the name of the main
%   function to define, and the name of the auxiliary which
%   performs the loop.
%
%   The looping auxiliary |#3| finds the next escape character,
%   reads the following two characters, and tests them. The test
%   \cs{str_aux_hexadecimal_use:NTF} leaves the upper-case digit
%   in the input stream, hence we surround the test with
%   \cs{str_output_byte:w}~|"| and \cs{str_output_end:}.
%   If both characters are hexadecimal digits, they should be
%   removed before looping: this is done by \cs{use_i:nnn}.
%   If one of the characters is not a hexadecimal digit,
%   then feed |"#1| to \cs{str_output_byte:w} to produce the
%   escape character, and call the looping function followed
%   by the two characters (remove \cs{use_i:nnn}).
%    \begin{macrocode}
\cs_set_protected:Npn \str_tmp:w #1#2#3
  {
    \group_begin:
      \char_set_lccode:nn {`\*} {"#1}
      \tl_to_lowercase:n
        {
          \group_end:
          \cs_new_protected_nopar:Npn #2
            {
              \tl_gset:Nx \g_str_result_tl
                {
                  \exp_after:wN #3 \g_str_result_tl
                    * ? { ? \prg_map_break: }
                  \prg_break_point:n { }
                }
            }
          \cs_new_nopar:Npn #3 ##1*##2##3
        }
            {
              \str_filter_bytes:n {##1}
              \use_none:n ##3
              \str_output_byte:w "
                \str_aux_hexadecimal_use:NTF ##2
                  {
                    \str_aux_hexadecimal_use:NTF ##3
                      { }
                      { * \c_zero + "#1 \use_i:nn }
                  }
                  { #1 \use_i:nn }
              \str_output_end:
              \use_i:nnn #3 ##2##3
            }
  }
\str_tmp:w {23} \str_convert_input_name: \str_convert_input_name_aux:wNN
\str_tmp:w {25} \str_convert_input_url:  \str_convert_input_url_aux:wNN
\cs_new_eq:NN \str_convert_input_percent: \str_convert_input_url:
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_input_string:}
% \begin{macro}[aux, rEXP]{\str_convert_input_string_aux:wN}
% \begin{macro}[aux, rEXP]{\str_convert_input_string_aux:wNNN}
% \begin{macro}[aux, rEXP]{\str_convert_input_string_aux:NNNNNN}
%   The \texttt{string} escaping is somewhat similar to
%   the \texttt{name} and \texttt{url} escapings, with
%   escape character |\|.
%   The first step is to convert all three line endings,
%   |^^J|, |^^M|, and |^^M^^J| to the common |^^J|, as per
%   the \textsc{pdf} specification.
%   Then the following escape sequences are decoded.
%   \begin{itemize}\def\makelabel#1{\hss\llap{\ttfamily\string#1}}
%   \item[\n] Line feed ($10$)
%   \item[\r] Carriage return ($13$)
%   \item[\t] Horizontal tab ($9$)
%   \item[\b] Backspace ($8$)
%   \item[\f] Form feed ($12$)
%   \item[\(] Left parenthesis
%   \item[\)] Right parenthesis
%   \item[\\] Backslash
%   \item[\ddd] (backslash followed by $1$ to $3$ octal digits)
%     Byte \texttt{ddd} (octal), subtracting $256$ in case of overflow.
%   \end{itemize}
%   If followed by an end-of-line character, the backslash and
%   the end-of-line are ignored. If followed by anything else,
%   the backslash is ignored.
%    \begin{macrocode}
\group_begin:
  \char_set_lccode:nn {`\*} {`\\}
  \char_set_catcode_other:N \^^J
  \char_set_catcode_other:N \^^M
  \tl_to_lowercase:n
    {
      \cs_new_protected_nopar:Npn \str_convert_input_string:
        {
          \tl_gset:Nx \g_str_result_tl
            {
              \exp_after:wN \str_convert_input_string_aux:wN
                \g_str_result_tl \prg_map_break: ^^M ?
              \prg_break_point:n { }
            }
          \tl_gset:Nx \g_str_result_tl
            {
              \exp_after:wN \str_convert_input_string_aux:wNNN
                \g_str_result_tl * ?? { ? \prg_map_break: }
              \prg_break_point:n { }
            }
        }
      \cs_new_nopar:Npn \str_convert_input_string_aux:wNNN #1 *#2#3#4
    }
        {
          \str_filter_bytes:n {#1}
          \use_none:n #4
          \str_output_byte:w '
            \str_aux_octal_use:NTF #2
              {
                \str_aux_octal_use:NTF #3
                  {
                    \str_aux_octal_use:NTF #4
                      {
                        \if_int_compare:w #2 > \c_three
                          - 256
                        \fi:
                        \str_convert_input_string_aux:NNNNNN
                      }
                      { \str_convert_input_string_aux:NNNNNN ? }
                  }
                  { \str_convert_input_string_aux:NNNNNN ?? }
              }
              {
                \prg_case_str:xxn {#2}
                  {
                    { \c_backslash_str } { 134 }
                    { ( } { 50 }
                    { ) } { 51 }
                    { r } { 15 }
                    { f } { 14 }
                    { n } { 12 }
                    { t } { 11 }
                    { b } { 10 }
                    { ^^J } { 0 - \c_one }
                  }
                  { 0 - \c_one \use_i:nn }
              }
          \str_output_end:
          \use_i:nn \str_convert_input_string_aux:wNNN #2#3#4
        }
  \cs_new_nopar:Npn \str_convert_input_string_aux:NNNNNN #1#2#3#4#5#6
    { \str_output_end: \str_convert_input_string_aux:wNNN }
  \cs_new_nopar:Npn \str_convert_input_string_aux:wN #1 ^^M #2
    {
      #1 ^^J
      \if_charcode:w ^^J #2
        \exp_after:wN \use_i:nn
      \fi:
      \str_convert_input_string_aux:wN #2
    }
\group_end:
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsubsection{Output bytes}
%
% \begin{macro}[int]{\str_convert_output_:}
% \begin{macro}[int]{\str_convert_output_bytes:}
%   The simplest form of output leaves the bytes from the previous
%   step of the conversion unchanged.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_output_: { }
\cs_new_eq:NN \str_convert_output_bytes: \str_convert_output_:
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_output_hex:}
% \begin{macro}[int]{\str_convert_output_hexadecimal:}
% \begin{macro}[aux, rEXP]{\str_convert_output_hex_aux:N}
%   Loop with expansion, and convert each byte to hexadecimal.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_output_hex:
  { \str_aux_gmap_result:N \str_convert_output_hex_aux:N }
\cs_new_nopar:Npn \str_convert_output_hex_aux:N #1
  { \str_output_hexadecimal:n { `#1 } }
\cs_new_eq:NN \str_convert_output_hexadecimal: \str_convert_output_hex:
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_output_name:}
% \begin{macro}[aux, rEXP]{\str_convert_output_name_aux:N}
% \begin{macro}[aux, rEXP]{\str_convert_output_name_aux:NTF}
% \begin{variable}{\c_str_convert_output_name_str}
% \begin{variable}{\c_str_convert_output_name_not_str}
%   Loop with expansion. For each byte, test whether it should
%   be output as is, or be \enquote{hash-encoded}.
%   Roughly, bytes outside the range from |"2A| to |"7E|
%   are hash-encoded. We keep two lists of exceptions:
%   characters in \cs{c_str_convert_output_name_not_str}
%   are not hash-encoded, and characters in the
%   \cs{c_str_convert_output_name_str} are encoded.
%    \begin{macrocode}
\str_const:Nn \c_str_convert_output_name_not_str { ! " $ & ' } %$
\str_const:Nn \c_str_convert_output_name_str { {}/<>[] }
\cs_new_protected_nopar:Npn \str_convert_output_name:
  { \str_aux_gmap_result:N \str_convert_output_name_aux:N }
\cs_new_nopar:Npn \str_convert_output_name_aux:N #1
  {
    \str_convert_output_name_aux:NTF #1 {#1}
      { \c_hash_str \str_output_hexadecimal:n {`#1} }
  }
\prg_new_conditional:Npnn \str_convert_output_name_aux:N #1 { TF }
  {
    \if_num:w `#1 < "2A \exp_stop_f:
      \str_if_contains_char:NNTF \c_str_convert_output_name_not_str #1
        \prg_return_true: \prg_return_false:
    \else:
      \if_num:w `#1 > "7E \exp_stop_f:
        \prg_return_false:
      \else:
        \str_if_contains_char:NNTF \c_str_convert_output_name_str #1
          \prg_return_false: \prg_return_true:
      \fi:
    \fi:
  }
%    \end{macrocode}
% \end{variable}
% \end{variable}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_output_string:}
% \begin{macro}[aux, rEXP]{\str_convert_output_string_aux:N}
% \begin{macro}[aux, rEXP]{\str_convert_output_string_aux:NTF}
% \begin{variable}{\c_str_convert_output_string_str}
%   Any character below (and including) space, and any character
%   above (and including) \texttt{del}, are converted to octal.
%   One backslash is added before each parenthesis and backslash.
%    \begin{macrocode}
\str_const:Nx \c_str_convert_output_string_str
  { \c_backslash_str ( ) }
\cs_new_protected_nopar:Npn \str_convert_output_string:
  { \str_aux_gmap_result:N \str_convert_output_string_aux:N }
\cs_new_nopar:Npn \str_convert_output_string_aux:N #1
  {
    \str_convert_output_string_aux:NTF #1
      {
        \str_if_contains_char:NNT
          \c_str_convert_output_string_str #1
          { \c_backslash_str }
        #1
      }
      {
        \c_backslash_str
        \int_div_truncate:nn {`#1} {64}
        \int_mod:nn { \int_div_truncate:nn {`#1} \c_eight } \c_eight
        \int_mod:nn {`#1} \c_eight
      }
  }
\prg_new_conditional:Npnn \str_convert_output_string_aux:N #1 { TF }
  {
    \if_num:w `#1 < "21 \exp_stop_f:
      \prg_return_false:
    \else:
      \if_num:w `#1 > "7E \exp_stop_f:
        \prg_return_false:
      \else:
        \prg_return_true:
      \fi:
    \fi:
  }
%    \end{macrocode}
% \end{variable}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_output_url:}
% \begin{macro}[int]{\str_convert_output_percent:}
% \begin{macro}[aux, rEXP]{\str_convert_output_url_aux:N}
% \begin{macro}[aux, rEXP]{\str_convert_output_url_aux:NTF}
%^^A todo: Figure out what bytes should be percent encoded! Safe could be
%^^A     !'()*-./0123456789_
%   This function is similar to \cs{str_convert_output_name:},
%   escaping different characters.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_output_url:
  { \str_aux_gmap_result:N \str_convert_output_url_aux:N }
\cs_new_nopar:Npn \str_convert_output_url_aux:N #1
  {
    \str_convert_output_url_aux:NTF #1 {#1}
      { \c_percent_str \str_output_hexadecimal:n { `#1 } }
  }
\prg_new_conditional:Npnn \str_convert_output_url_aux:N #1 { TF }
  {
    \if_num:w `#1 < "41 \exp_stop_f:
      \str_if_contains_char:nNTF { "-.<> } #1
        \prg_return_true: \prg_return_false:
    \else:
      \if_num:w `#1 > "7E \exp_stop_f:
        \prg_return_false:
      \else:
        \str_if_contains_char:nNTF { [ ] } #1
          \prg_return_false: \prg_return_true:
      \fi:
    \fi:
  }
\cs_new_eq:NN \str_convert_output_percent: \str_convert_output_url:
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsubsection{Convert to and from native strings}
%
% \begin{macro}[int]{\str_convert_from_native:}
% \begin{macro}[aux, rEXP]{\str_convert_from_native_aux:N}
%   Convert each character to its character code, one at a time.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_from_native:
  { \str_aux_gmap_result:N \str_convert_from_native_aux:N }
\cs_new:Npn \str_convert_from_native_aux:N #1
  { \int_value:w `#1 , }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_to_native:}
% \begin{macro}[aux]{\str_convert_to_native_aux:w}
%   Convert the string from the given encoding
%   to the internal format. We grab integers
%   from the internal string using the low-level
%   method to assign integers.
%   Except at the end of the loop, the function
%   \cs{str_convert_to_native_aux:w} is followed by a
%   comma, hence its argument is empty.
%   We are making heavy use of \TeX{} primitives here,
%   because the function can become very slow for large
%   strings.
%    \begin{macrocode}
\cs_new_protected_nopar:Npn \str_convert_to_native:
  {
    \tl_gset_eq:NN \g_str_tmpa_tl \g_str_result_tl
    \tl_gclear:N \g_str_result_tl
    \tex_afterassignment:D \str_convert_to_native_aux:w
    \l_str_char_int = \g_str_tmpa_tl \c_zero \prg_map_break: ,
    \prg_break_point:n { }
  }
\group_begin:
  \char_set_catcode_other:n { `\^^@ }
  \cs_new_protected_nopar:Npn \str_convert_to_native_aux:w #1 ,
    {
      #1
      \if_int_compare:w \l_str_char_int > \c_max_char_int
        \msg_kernel_error:nnx { str } { overflow }
          { \int_use:N \l_str_char_int }
      \else:
        \tex_lccode:D \c_zero \l_str_char_int
        \tl_to_lowercase:n
          { \tex_xdef:D \g_str_result_tl { \g_str_result_tl ^^@ } }
      \fi:
      \tex_afterassignment:D \str_convert_to_native_aux:w
      \l_str_char_int =
    }
\group_end:
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \subsubsection{\textsc{utf-16} support}
%
% The definitions are done in a category code regime where
% the bytes $254$ and $255$ used by the byte order mark
% have catcode \enquote{other}.
%    \begin{macrocode}
\group_begin:
  \char_set_catcode_other:N \^^fe
  \char_set_catcode_other:N \^^ff
%    \end{macrocode}
%
% \begin{macro}[int]{\str_convert_to_utf16:}
% \begin{macro}[int]{\str_convert_to_utf16be:}
% \begin{macro}[int]{\str_convert_to_utf16le:}
% \begin{macro}[aux, rEXP]
%   {
%     \str_aux_to_utf_xvi:n,
%     \str_aux_to_utf_xvi_be:n,
%     \str_aux_to_utf_xvi_le:n
%   }
%   Convert characters one by one in a loop, with different
%   behaviours depending on the character code:
%   \begin{itemize}
%   \item $[0, 55295]$ converted to two bytes;
%   \item $[55296, 57343]$ cannot be converted, replaced by
%     the replacement character;
%   \item $[57344, 65535]$ converted to two bytes;
%   \item $[65536, 1114111]$ converted to a pair of surrogates,
%     each two bytes.
%   \end{itemize}
%   For the duration of this operation, \cs{str_tmp:w} is defined
%   as a function to convert a number in the range $[0, 65536]$
%   to a pair of bytes (either big endian or little endian).
%    \begin{macrocode}
  \cs_new_protected_nopar:cpx { str_convert_to_utf16: }
    {
      \exp_not:c { str_convert_to_utf16be: }
      \exp_not:n { \tl_gput_left:Nx \g_str_result_tl { ^^fe ^^ff } }
    }
  \cs_new_protected_nopar:cpn { str_convert_to_utf16be: }
    {
      \cs_set_eq:NN \str_tmp:w \str_aux_to_utf_xvi_be:n
      \str_aux_gmap_internal_result:N \str_aux_to_utf_xvi:n
    }
  \cs_new_protected_nopar:cpn { str_convert_to_utf16le: }
    {
      \cs_set_eq:NN \str_tmp:w \str_aux_to_utf_xvi_le:n
      \str_aux_gmap_internal_result:N \str_aux_to_utf_xvi:n
    }
  \cs_new_nopar:Npn \str_aux_to_utf_xvi:n #1
    {
      \if_int_compare:w #1 < "D800 \exp_stop_f:
        \str_tmp:w {#1}
      \else:
        \if_int_compare:w #1 < "10000 \exp_stop_f:
          \if_int_compare:w #1 < "E000 \exp_stop_f:
            \msg_expandable_kernel_error:nnn
              { str } { unicode-surrogate } {#1}
            \str_tmp:w { \c_str_replacement_char_int }
          \else:
            \str_tmp:w {#1}
          \fi:
        \else:
          \exp_args:Nf \str_tmp:w { \int_div_truncate:nn {#1} {"400} + "D800 }
          \exp_args:Nf \str_tmp:w { \int_mod:nn {#1} {"400} + "DC00 }
        \fi:
      \fi:
    }
  \cs_new_nopar:Npn \str_aux_to_utf_xvi_be:n #1
    {
      \str_output_byte:n { \int_div_truncate:nn {#1} {"100} }
      \str_output_byte:n { \int_mod:nn {#1} {"100} }
    }
  \cs_new_nopar:Npn \str_aux_to_utf_xvi_le:n #1
    {
      \str_output_byte:n { \int_mod:nn {#1} {"100} }
      \str_output_byte:n { \int_div_truncate:nn {#1} {"100} }
    }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]
%   {
%     \str_convert_from_utf16:,
%     \str_convert_from_utf16be:,
%     \str_convert_from_utf16le:
%   }
% \begin{macro}[aux]{\str_aux_from_utf_xvi_bom:NNw}
% \begin{macro}[aux]{\str_aux_from_utf_xvi:No}
%   Define \cs{str_tmp:w} to take two arguments and return the
%   character code of the first one if the string is big-endian,
%   and the second one if the string is little-endian.
%   If the endianness is not known, look for a byte order mark
%   to decide.
%    \begin{macrocode}
  \cs_new_protected_nopar:cpn { str_convert_from_utf16be: }
    { \str_aux_from_utf_xvi:No 1 { \g_str_result_tl } }
  \cs_new_protected_nopar:cpn { str_convert_from_utf16le: }
    { \str_aux_from_utf_xvi:No 2 { \g_str_result_tl } }
  \cs_new_protected_nopar:cpn { str_convert_from_utf16: }
    {
      \exp_after:wN \str_aux_from_utf_xvi_bom:NNw
        \g_str_result_tl \scan_stop: \scan_stop: \scan_stop:
    }
  \cs_new_protected_nopar:Npn
      \str_aux_from_utf_xvi_bom:NNw #1#2#3\scan_stop:
    {
      \str_if_eq:nnTF { #1#2 } { ^^ff ^^fe }
        { \str_aux_from_utf_xvi:No 2 {#3} }
        {
          \str_if_eq:nnTF { #1#2 } { ^^fe ^^ff }
            { \str_aux_from_utf_xvi:No 1 {#3} }
            { \str_aux_from_utf_xvi:No 1 {#1#2#3} }
        }
    }
  \cs_new_protected_nopar:Npn \str_aux_from_utf_xvi:No #1#2
    {
      \cs_set_nopar:Npn \str_tmp:w ##1 ##2 { ` ## #1 }
      \tl_gset:Nx \g_str_result_tl
        {
          \exp_after:wN \str_aux_from_utf_xvi:NN
            #2 \scan_stop: \scan_stop:
          \prg_break_point:n { }
        }
    }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[aux, rEXP]{\str_aux_from_utf_xvi:NN}
% \begin{macro}[aux, rEXP]{\str_aux_from_utf_xvi:wNNN}
% \begin{macro}[aux, rEXP]{\str_aux_from_utf_xvi_error:wNNw}
% \begin{macro}[aux, rEXP]{\str_aux_from_utf_xvi_end:Nw}
% \begin{macro}[aux, rEXP]{\str_aux_from_utf_xvi_end:wNNww}
%   When \cs{str_aux_from_utf_xvi:NN} is called, \cs{str_tmp:w}
%   is such that |\str_tmp:w #1#2| expands to |`#1| if the string
%   is big-endian, and |`#2| if the string is little-endian.
%   If the most significant byte is between |"D8| and |"DB|
%   inclusive, then the pair of bytes is a high surrogate,
%   and we fetch the following pair, which must be a low surrogate,
%   \emph{i.e.}, between |"DC| and |"DF| inclusive.
%   Unpaired surrogates are errors, handled with
%   \cs{str_aux_from_utf_xvi_error:wNNw}.
%    \begin{macrocode}
  \cs_new:Npn \str_aux_from_utf_xvi:NN #1#2
    {
      \if_meaning:w \scan_stop: #2
        \str_aux_from_utf_xvi_end:Nw #1
      \fi:
      \int_use:N \int_eval:w
        \if_case:w
          \int_eval:w ( \str_tmp:w #1#2 - "D6 ) / \c_four \int_eval_end:
        \or: \exp_after:wN \str_aux_from_utf_xvi:wNNN
        \or: \exp_after:wN \str_aux_from_utf_xvi_error:wNNw
        \fi:
        "100 * \str_tmp:w #1#2 + \str_tmp:w #2#1 ,
      \str_aux_from_utf_xvi:NN
    }
  \cs_new:Npn \str_aux_from_utf_xvi:wNNN #1, #2#3#4
    {
      \if_meaning:w \scan_stop: #4
        \str_aux_from_utf_xvi_end:wNNww #1 , #3
      \fi:
      \if_num:w \int_eval:w ( \str_tmp:w #3#4 - "DA ) / \c_four = \c_one
        ( #1 - "D800 ) * "400
          + \str_tmp:w #3#4 * "100 + \str_tmp:w #4#3 - "DC00 ,
        \exp_after:wN \use_i:nnn
      \else:
        \str_aux_from_utf_xvi_error:wNNw #1 ,
      \fi:
      #2#3#4
    }
  \cs_new:Npn \str_aux_from_utf_xvi_error:wNNw #1 \str_tmp:w #2#3 #4,
    {
      \msg_expandable_kernel_error:nnn
        { str } { utf16-surrogate } { #2#3 }
      \c_str_replacement_char_int ,
    }
  \cs_new:Npn \str_aux_from_utf_xvi_end:Nw #1 \fi:
    {
      \fi:
      \if_meaning:w \scan_stop: #1
      \else:
        \msg_expandable_kernel_error:nnn
          { str } { utf16-odd } {#1}
        \c_str_replacement_char_int ,
      \fi:
      \prg_map_break:
    }
  \cs_new:Npn \str_aux_from_utf_xvi_end:wNNww #1 `#2#3 #4, #5 \fi:
    {
      \fi:
      \if_meaning:w \scan_stop: #5
        \msg_expandable_kernel_error:nnn
          { str } { utf16-surrogate } { #2#3 }
      \else:
        \msg_expandable_kernel_error:nnn
          { str } { utf16-odd } { #2#3#5 }
      \fi:
      \c_str_replacement_char_int ,
      \prg_map_break:
    }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% Restore the original catcodes of bytes $254$ and $255$.
%    \begin{macrocode}
\group_end:
%    \end{macrocode}
%
% \subsubsection{\textsc{utf-8} support}
%
% \begin{macro}[int]{\str_convert_to_utf8:}
% \begin{macro}[aux, rEXP]
%   {
%     \str_aux_to_utf_viii:n,
%     \str_aux_to_utf_viii:nnnnw
%   }
%   Loop through the internal string, and convert each character
%   to the \textsc{utf-8} representation. The details are messy.
%^^A todo: document.
%    \begin{macrocode}
\cs_new_protected_nopar:cpn { str_convert_to_utf8: }
  { \str_aux_gmap_internal_result:N \str_aux_to_utf_viii:n }
\cs_new:Npn \str_aux_to_utf_viii:n #1
  {
    \str_aux_to_utf_viii:nnnnw
      {#1} { \c_minus_one + \c_zero * \use_none:n }
      { 128 } { \c_zero }
      {  32 } {     192 }
      {  16 } {     224 }
      {   8 } {     240 }
    \q_stop
  }
\cs_new_nopar:Npn \str_aux_to_utf_viii:nnnnw #1#2#3#4 #5 \q_stop
  {
    \if_num:w #1 < #3 \exp_stop_f:
      \str_output_byte:n { #1 + #4 }
    \else:
      \exp_args:Nf \str_aux_to_utf_viii:nnnnw
        { \int_div_truncate:nn {#1} {64} }
        {#1}
        #5 \q_stop
    \fi:
    \str_output_byte:n { #2 - 64 * ( #1 - \c_two ) }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_convert_from_utf8:}
% \begin{macro}[aux, rEXP]
%   {
%     \str_aux_from_utf_viii:N,
%     \str_aux_from_utf_viii:wwNN,
%     \str_aux_from_utf_viii:wNNww
%   }
% \begin{macro}[aux, rEXP]
%   {
%     \str_aux_from_utf_viii_error:w,
%     \str_aux_from_utf_viii_error:NwNN,
%     \str_aux_from_utf_viii_error:
%   }
%   In the \textsc{utf-8} encoding, bytes in the range $[0,127]$ stand
%   for themselves, bytes in the range $[128,191]$ are continuation bytes,
%   and larger bytes must be followed by a number of continuation bytes.
%   Documentation to come.
% ^^A todo: refuse "D800 -- "DFFF?
% ^^A todo: document
% ^^A todo: what error recovery for code points > "10FFFF?
%    \begin{macrocode}
\cs_new_protected_nopar:cpn { str_convert_from_utf8: }
  {
    \tl_gset:Nx \g_str_result_tl
      {
        \exp_after:wN \str_aux_from_utf_viii:N \g_str_result_tl
          { ? \prg_map_break: \q_stop \str_aux_from_utf_viii_error: }
        \prg_break_point:n { }
      }
  }
\cs_new_nopar:Npn \str_aux_from_utf_viii:N #1
  {
    \use_none:n #1
    \int_use:N \int_eval:w
      \if_num:w `#1 < "C0 \exp_stop_f:
        \if_num:w `#1 < "80 \exp_stop_f:
          `#1
        \else:
          \msg_expandable_kernel_error:nnn
            { str } { utf8-extra-conti } {#1}
          \c_str_replacement_char_int
        \fi:
      \else:
        \if_num:w `#1 < "F5 \exp_stop_f:
          \exp_after:wN \str_aux_from_utf_viii:wwNN
            \int_use:N \int_eval:w `#1 - "C0
        \else:
          \msg_expandable_kernel_error:nnn
            { str } { utf8-invalid-byte } {#1}
          \c_str_replacement_char_int
        \fi:
      \fi:
    ,
    \use_none_delimit_by_q_stop:w
      "80 , "800 , "10000 , "10FFFF ,
    \q_stop
    \str_aux_from_utf_viii:N
  }
\cs_new_nopar:Npn \str_aux_from_utf_viii:wwNN #1 , #2 \q_stop #3#4
  {
    \use_none_delimit_by_q_stop:w #4 \q_stop
    \exp_after:wN \str_aux_from_utf_viii:wNNww
      \int_use:N \int_eval:w #1 * "40 + `#4 - "80 ,
      #4
      #2
    \q_stop #3
  }
\cs_new_nopar:Npn \str_aux_from_utf_viii:wNNww #1, #2 #3#4, #5,
  {
    \if_num:w \int_eval:w ( `#2 + \c_thirty_two ) / "40 = \c_three
      \if_num:w #1 < #4 \exp_stop_f:
        \str_aux_from_utf_viii_error:w #1 ,
      \else:
        \if_num:w #1 < #5 \exp_stop_f:
          #1
        \else:
          \exp_after:wN \str_aux_from_utf_viii:wwNN
            \int_use:N \int_eval:w #1 - #5
        \fi:
      \fi:
    \else:
      \exp_after:wN \str_aux_from_utf_viii_error:NwN
      \exp_after:wN #2
    \fi:
    , #3#5,
  }
\cs_new_nopar:Npn \str_aux_from_utf_viii_error:w #1 ,
  {
    \msg_expandable_kernel_error:nnn
      { str } { utf8-overlong } {#1}
    \c_str_replacement_char_int
  }
\cs_new_nopar:Npn \str_aux_from_utf_viii_error:NwN #1 #2 \q_stop #3
  {
    \msg_expandable_kernel_error:nnn
      { str } { utf8-missing-conti } {#1}
    \c_str_replacement_char_int ,
    #3#1
  }
\cs_new_nopar:Npn \str_aux_from_utf_viii_error:
  {
    \msg_expandable_kernel_error:nn
      { str } { utf8-premature-end }
    \c_str_replacement_char_int ,
    \prg_map_break:
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsubsection{\textsc{utf-32} support}
%
% The definitions are done in a category code regime where
% the bytes $0$, $254$ and $255$ used by the byte order mark
% have catcode \enquote{other}.
%    \begin{macrocode}
\group_begin:
  \char_set_catcode_other:N \^^00
  \char_set_catcode_other:N \^^fe
  \char_set_catcode_other:N \^^ff
%    \end{macrocode}
%
% \begin{macro}[int]
%   {
%     \str_convert_to_utf32:,
%     \str_convert_to_utf32be:,
%     \str_convert_to_utf32le:
%   }
% \begin{macro}[aux, rEXP]
%   {
%     \str_aux_to_utf_xxxii_be:n,
%     \str_aux_to_utf_xxxii_le:n
%   }
%   Convert each integer in the comma-list \cs{g_str_result_tl}
%   to a sequence of four bytes. The functions for big-endian
%   and little-endian encodings are very similar, but the
%   \cs{str_output_byte:n} instructions are reversed.
%    \begin{macrocode}
  \cs_new_protected_nopar:cpx { str_convert_to_utf32: }
    {
      \exp_not:c { str_convert_to_utf32be: }
      \exp_not:n { \tl_gput_left:Nx \g_str_result_tl { ^^00 ^^00 ^^fe ^^ff } }
    }
  \cs_new_protected_nopar:cpn { str_convert_to_utf32be: }
    { \str_aux_gmap_internal_result:N \str_aux_to_utf_xxxii_be:n }
  \cs_new_protected_nopar:cpn { str_convert_to_utf32le: }
    { \str_aux_gmap_internal_result:N \str_aux_to_utf_xxxii_le:n }
  \cs_new:Npn \str_aux_to_utf_xxxii_be:n #1
    {
      ^^00
      \str_output_byte:n { \int_div_truncate:nn {#1} { "10000 } }
      \str_output_byte:n
        { \int_mod:nn { \int_div_truncate:nn {#1} {"100} } {"100} }
      \str_output_byte:n { \int_mod:nn {#1} {"100} }
    }
  \cs_new:Npn \str_aux_to_utf_xxxii_le:n #1
    {
      \str_output_byte:n { \int_mod:nn {#1} {"100} }
      \str_output_byte:n
        { \int_mod:nn { \int_div_truncate:nn {#1} {"100} } {"100} }
      \str_output_byte:n { \int_div_truncate:nn {#1} { "10000 } }
      ^^00
    }
%    \end{macrocode}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]
%   {
%     \str_convert_from_utf32:,
%     \str_convert_from_utf32be:,
%     \str_convert_from_utf32le:
%   }
% \begin{macro}[aux]
%   {
%     \str_aux_from_utf_xxxii_bom:NNNNw,
%     \str_aux_from_utf_xxxii:No
%   }
% \begin{macro}[aux, rEXP]
%   {
%     \str_aux_from_utf_xxxii:NNNN,
%     \str_aux_from_utf_xxxii_end:ww
%   }
%   See the conversion functions from \textsc{utf-16} encodings.
%   The \cs{str_aux_from_utf_xxxii:No} auxiliary defines
%   \cs{str_tmp:w} to take two arguments and give the character
%   code of either the first argument (big-endian) or the second
%   argument (little-endian). Then we loop over the string,
%   four bytes at a time, check for overflow, and otherwise
%   produce the number corresponding to the four bytes with
%   the given endianness.
%    \begin{macrocode}
  \cs_new_protected_nopar:cpn { str_convert_from_utf32be: }
    { \str_aux_from_utf_xxxii:No 1 { \g_str_result_tl } }
  \cs_new_protected_nopar:cpn { str_convert_from_utf32le: }
    { \str_aux_from_utf_xxxii:No 2 { \g_str_result_tl } }
  \cs_new_protected_nopar:cpn { str_convert_from_utf32: }
    {
      \exp_after:wN \str_aux_from_utf_xxxii_bom:NNNNw \g_str_result_tl
        \scan_stop: \scan_stop: \scan_stop: \scan_stop: \scan_stop:
    }
  \cs_new_protected_nopar:Npn
      \str_aux_from_utf_xxxii_bom:NNNNw #1#2#3#4#5\scan_stop:
    {
      \str_if_eq:nnTF { #1#2#3#4 } { ^^ff ^^fe ^^00 ^^00 }
        { \str_aux_from_utf_xxxii:No 2 {#5} }
        {
          \str_if_eq:nnTF { #1#2#3#4 } { ^^00 ^^00 ^^fe ^^ff }
            { \str_aux_from_utf_xxxii:No 1 {#5} }
            { \str_aux_from_utf_xxxii:No 1 {#1#2#3#4#5} }
        }
    }
  \cs_new_protected_nopar:Npn \str_aux_from_utf_xxxii:No #1#2
    {
      \cs_set_nopar:Npn \str_tmp:w ##1 ##2 { ` ## #1 }
      \tl_gset:Nx \g_str_result_tl
        {
          \exp_after:wN \str_aux_from_utf_xxxii:NNNN
            #2 \scan_stop: \scan_stop: \scan_stop: \scan_stop:
          \prg_break_point:n { }
        }
    }
  \cs_new:Npn \str_aux_from_utf_xxxii:NNNN #1#2#3#4
    {
      \if_meaning:w \scan_stop: #4
        \str_aux_from_utf_xxxii_end:ww #1#2#3#4
      \fi:
      \int_use:N \int_eval:w
        \if_num:w \int_eval:w
                    \str_tmp:w #1#4 * \c_two_hundred_fifty_six
                    + \str_tmp:w #2#3
                  > \c_sixteen
          \msg_expandable_kernel_error:nnn
            { str } { utf32-overflow } { #1#2#3#4 }
          \c_str_replacement_char_int
        \else:
          \str_tmp:w #2#3*"10000
          + \str_tmp:w #3#2 * \c_two_hundred_fifty_six
          + \str_tmp:w #4#1
        \fi:
      ,
      \str_aux_from_utf_xxxii:NNNN
    }
  \cs_new:Npn \str_aux_from_utf_xxxii_end:ww #1 \scan_stop: #2 \fi:
    {
      \fi:
      \tl_if_empty:nF {#1}
        {
          \msg_expandable_kernel_error:nnn
            { str } { utf32-truncated } { #1 }
        }
      \prg_map_break:
    }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% Restore the original catcodes of bytes $0$, $254$ and $255$.
%    \begin{macrocode}
\group_end:
%    \end{macrocode}
%
% \subsubsection{Loading encoding files}
%^^A todo: rename all functions here
%^^A todo: document
%
% \begin{macro}{\str_load_encoding:n}
% \begin{macro}[aux]{\str_load_encoding_catcodes:}
% \begin{macro}[aux]{\str_load_encoding_one:n}
%
%    \begin{macrocode}
\cs_new_protected:Npn \str_load_encoding_catcodes:
  {
    \char_set_catcode_escape:N \\
    \char_set_catcode_group_begin:N \{
    \char_set_catcode_group_end:N \}
    \char_set_catcode_math_superscript:N \^
    \char_set_catcode_ignore:N \ %
    \tl_map_function:nN { abcdefghijklmnopqrstuvwxyz_:N }
      \char_set_catcode_letter:N
    \tl_map_function:nN { 0123456789ABCDEF"'? }
      \char_set_catcode_other:N
    \char_set_catcode_comment:N \%
    \int_set:Nn \tex_endlinechar:D {32}
  }
\cs_new_protected:Npn \str_load_encoding:n #1
  {
    \group_begin:
      \str_load_encoding_catcodes:
      \clist_map_inline:nn {#1}
        {
          \exp_args:Nx \str_load_encoding_one:n
            { \str_aux_lowercase_alphanum:n {#1} }
        }
    \group_end:
  }
\cs_new_protected:Npn \str_load_encoding_one:n #1
  {
    \cs_if_exist:cF { str_convert_from_ #1 : }
      {
        \file_if_exist:nTF { l3str- #1 .def }
          { \file_input:n { l3str- #1 .def } }
          {
            \msg_kernel_error:nnx
              { str } { encoding-file-not-found } {#1}
          }
      }
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% Some functions that should be used within encoding definition files.
%
% \begin{macro}[int]{\str_load_encoding_basic:n}
% \begin{macro}[int]{\str_aux_basic_from_byte:N}
% \begin{macro}[int]{\str_aux_basic_to_byte:n}
% \begin{macro}[aux]{\str_aux_basic_to_byte_ii:n}
%    \begin{macrocode}
\cs_new_protected:Npn \str_load_encoding_basic:n #1
  {
    \cs_new_protected:cpn { str_convert_from_#1: }
      {
        \group_begin:
          \cs_set_eq:NN \str_load_encoding_aux:nn \str_load_encoding_from:nn
          \int_zero:N \l_str_encoding_int
          \tl_use:c { c_str_encoding_#1_tl }
          \str_aux_gmap_result:N \str_aux_basic_from_byte:N
        \group_end:
      }
    \cs_new_protected:cpn { str_convert_to_#1: }
      {
        \group_begin:
          \cs_set_eq:NN \str_load_encoding_aux:nn \str_load_encoding_to:nn
          \int_zero:N \l_str_encoding_int
          \tl_use:c { c_str_encoding_#1_tl }
          \str_aux_gmap_internal_result:N \str_aux_basic_to_byte:n
        \group_end:
      }
  }
\cs_new:Npn \str_aux_basic_from_byte:N #1
  {
    \if_num:w \tex_dimen:D `#1 < \l_str_encoding_int
      \if_num:w \tex_skip:D \tex_dimen:D `#1 = `#1 \exp_stop_f:
        \tex_the:D \tex_toks:D \tex_dimen:D
      \fi:
    \fi:
    \int_value:w `#1 ,
  }
\cs_new:Npn \str_aux_basic_to_byte:n #1
  {
    \if_num:w #1 < "8000 \exp_stop_f:
      \if_num:w \tex_dimen:D #1 < \l_str_encoding_int
        \if_num:w \tex_skip:D \tex_dimen:D #1 = #1 \exp_stop_f:
          \tex_the:D \tex_toks:D \tex_dimen:D #1 \exp_stop_f:
          \exp_after:wN \exp_after:wN \exp_after:wN \use_none:nn
        \fi:
      \fi:
      \str_aux_basic_to_byte_ii:n {#1}
    \else:
      \msg_expandable_kernel_error:nnn
        { str } { basic-to-byte-overflow } {#1}
    \fi:
  }
\cs_new:Npn \str_aux_basic_to_byte_ii:n #1
  {
    \if_num:w #1 < \c_two_hundred_fifty_six
      \str_output_byte:n {#1}
    \else:
      \msg_expandable_kernel_error:nn { str } { basic-to-byte-unknown }
    \fi:
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \begin{macro}[int]{\str_load_encoding_aux:nn}
% \begin{macro}[int]{\str_load_encoding_from:nn}
% \begin{macro}[int]{\str_load_encoding_to:nn}
%    \begin{macrocode}
\int_new:N \l_str_encoding_int
\cs_new_eq:NN \str_load_encoding_aux:nn \prg_map_break:
\cs_new_protected_nopar:Npn \str_load_encoding_from:nn #1#2
  {
    \use_none_delimit_by_q_stop:w #1 \q_stop
    \tex_dimen:D "#1 = \l_str_encoding_int sp \scan_stop:
    \tex_skip:D \l_str_encoding_int = "#1 sp \scan_stop:
    \tex_toks:D \l_str_encoding_int \exp_after:wN { \int_value:w "#2 }
    \tex_advance:D \l_str_encoding_int \c_one
    \str_load_encoding_from:nn
  }
\cs_new_protected_nopar:Npn \str_load_encoding_to:nn #1#2
  {
    \use_none_delimit_by_q_stop:w #1 \q_stop
    \tex_dimen:D "#2 = \l_str_encoding_int sp \scan_stop:
    \tex_skip:D \l_str_encoding_int = "#2 sp \scan_stop:
    \exp_args:NNf \tex_toks:D \l_str_encoding_int
      { \str_output_byte:n { "#1 } }
    \tex_advance:D \l_str_encoding_int \c_one
    \str_load_encoding_to:nn
  }
%    \end{macrocode}
% \end{macro}
% \end{macro}
% \end{macro}
%
% \subsection{Messages}
%
%    \begin{macrocode}
\msg_kernel_new:nnnn { str } { x-missing-brace }
  { Missing~closing~brace~in~ \token_to_str:N \x ~byte~sequence. }
  {
    You~wrote~something~like~
    `\iow_char:N\\x\{ \int_to_hexadecimal:n { \l_str_char_int }'.~
    The~closing~brace~is~missing.
  }
\msg_kernel_new:nnnn { str } { overflow }
  { Character~code~#1~too~big. }
  {
    \int_compare:nNnTF {#1} > { 1114111 }
      { The~Unicode~standard~limits~code~points~to~1114111. }
      {
        The~pdfTeX~engine~only~supports~8-bit~characters:~
        valid~character~codes~are~in~the~range~[0,255].~
        To~manipulate~arbitrary~Unicode,~use~LuaTeX~or~XeTeX.
      }
  }
\msg_kernel_new:nnn { str } { convert-input }
  { Input~scheme~`#1'~unknown. }
\msg_kernel_new:nnn { str } { convert-from }
  { Encoding~`#1'~unknown. }
\msg_kernel_new:nnn { str } { convert-to }
  { Encoding~`#1'~unknown.~Using~UTF-8. }
\msg_kernel_new:nnn { str } { convert-output }
  { Output~scheme~`#1~unknown. }
\msg_kernel_new:nnn { str } { to-native }
  { Use~\str_set_convert:Nnn to~convert~to~native~strings. }
\msg_kernel_new:nnn { str } { unicode-surrogate }
  { Code~point~#1~is~an~unpaired~surrogate. }
\msg_kernel_new:nnn { str } { utf16-surrogate }
  { UTF-16~unpaired~surrogate~#1. }
\msg_kernel_new:nnn { str } { utf16-odd }
  { UTF-16~dangling~byte~#1. }
\msg_kernel_new:nnn { str } { utf8-extra-conti }
  { UTF-8~extra~continuation~byte~#1. }
\msg_kernel_new:nnn { str } { utf8-missing-conti }
  { UTF-8~missing~continuation~byte~#1. }
\msg_kernel_new:nnn { str } { utf8-invalid-byte }
  { Byte~#1~cannot~appear~in~UTF-8. }
\msg_kernel_new:nnn { str } { utf8-overlong }
  { Overlong~UTF-8~byte~sequence~for~code~point~#1. }
\msg_kernel_new:nnn { str } { utf8-premature-end }
  { Incomplete~last~UTF-8~character. }
\msg_kernel_new:nnn { str } { utf32-overflow }
  { Code~point~too~large~(UTF-32~`#1'). }
\msg_kernel_new:nnn { str } { utf32-truncated }
  { Truncated~UTF-32~string~`...#1'. }
%    \end{macrocode}
%
% \subsection{Deprecated string functions}
%
% \begin{macro}{\str_length_skip_spaces:N, \str_length_skip_spaces:n}
%   The naming scheme is a little bit more consistent
%   with \enquote{ignore_spaces} instead of \enquote{skip_spaces}.
%    \begin{macrocode}
\cs_set:Npn \str_length_skip_spaces:N
  { \exp_args:No \str_length_skip_spaces:n }
\cs_set_eq:NN \str_length_skip_spaces:n \str_length_ignore_spaces:n
%    \end{macrocode}
% \end{macro}
%
%    \begin{macrocode}
%</initex|package>
%    \end{macrocode}
%
% \subsubsection{\textsc{iso 8859} support}
%^^A todo: document
%^^A todo: automatically produce our files from
%^^A     http://unicode.org/Public/MAPPINGS/ISO8859/
%
% For now, we only provide the first four \textsc{iso-8859} code pages,
% as a testing ground for various possible implementations.
%
% The \textsc{iso-8859-1} encoding exactly matches with the $256$
% first Unicode characters.
%    \begin{macrocode}
%<*iso88591>
\str_load_encoding_basic:n { iso88591 }
\tl_const:cn { c_str_encoding_iso88591_tl } { }
%</iso88591>
%    \end{macrocode}
%
% The \textsc{iso-8859-2} encoding exactly matches with the first $160$
% Unicode characters, and differs from Unicode for other bytes.
%    \begin{macrocode}
%<*iso88592>
\str_load_encoding_basic:n { iso88592 }
\tl_const:cn { c_str_encoding_iso88592_tl }
  {
    \str_load_encoding_aux:nn
      { A1 } { 0104 }
      { A2 } { 02D8 }
      { A3 } { 0141 }
      { A5 } { 013D }
      { A6 } { 015A }
      { A9 } { 0160 }
      { AA } { 015E }
      { AB } { 0164 }
      { AC } { 0179 }
      { AE } { 017D }
      { AF } { 017B }
      { B1 } { 0105 }
      { B2 } { 02DB }
      { B3 } { 0142 }
      { B5 } { 013E }
      { B6 } { 015B }
      { B7 } { 02C7 }
      { B9 } { 0161 }
      { BA } { 015F }
      { BB } { 0165 }
      { BC } { 017A }
      { BD } { 02DD }
      { BE } { 017E }
      { BF } { 017C }
      { C0 } { 0154 }
      { C3 } { 0102 }
      { C5 } { 0139 }
      { C6 } { 0106 }
      { C8 } { 010C }
      { CA } { 0118 }
      { CC } { 011A }
      { CF } { 010E }
      { D0 } { 0110 }
      { D1 } { 0143 }
      { D2 } { 0147 }
      { D5 } { 0150 }
      { D8 } { 0158 }
      { D9 } { 016E }
      { DB } { 0170 }
      { DE } { 0162 }
      { E0 } { 0155 }
      { E3 } { 0103 }
      { E5 } { 013A }
      { E6 } { 0107 }
      { E8 } { 010D }
      { EA } { 0119 }
      { EC } { 011B }
      { EF } { 010F }
      { F0 } { 0111 }
      { F1 } { 0144 }
      { F2 } { 0148 }
      { F5 } { 0151 }
      { F8 } { 0159 }
      { F9 } { 016F }
      { FB } { 0171 }
      { FE } { 0163 }
      { FF } { 02D9 }
      { \q_stop \prg_map_break: } { }
    \prg_break_point:n { }
  }
%</iso88592>
%    \end{macrocode}
%
%    \begin{macrocode}
%<*iso88593>
\str_load_encoding_basic:n { iso88593 }
\tl_const:cn { c_str_encoding_iso88593_tl }
  {
    \str_load_encoding_aux:nn
      { A1 } { 0126 }
      { A2 } { 02D8 } % missing A5
      { A6 } { 0124 }
      { A9 } { 0130 }
      { AA } { 015E }
      { AB } { 011E }
      { AC } { 0134 } % missing AE
      { AF } { 017B }
      { B1 } { 0127 }
      { B6 } { 0125 }
      { B9 } { 0131 }
      { BA } { 015F }
      { BB } { 011F }
      { BC } { 0135 } % missing BE
      { BF } { 017C } % missing C3
      { C5 } { 010A }
      { C6 } { 0108 } % missing D0
      { D5 } { 0120 }
      { D8 } { 011C }
      { DD } { 016C }
      { DE } { 015C } % missing E3
      { E5 } { 010B }
      { E6 } { 0109 } % missing F0
      { F5 } { 0121 }
      { F8 } { 011D }
      { FD } { 016D }
      { FE } { 015D }
      { FF } { 02D9 }
      { \q_stop \prg_map_break: } { }
    \prg_break_point:n { }
  }
%</iso88593>
%    \end{macrocode}
%
%    \begin{macrocode}
%<*iso88594>
\str_load_encoding_basic:n { iso88594 }
\tl_const:cn { c_str_encoding_iso88594_tl }
  {
    \str_load_encoding_aux:nn
      { A1 } { 0104 }
      { A2 } { 0138 }
      { A3 } { 0156 }
      { A5 } { 0128 }
      { A6 } { 013B }
      { A9 } { 0160 }
      { AA } { 0112 }
      { AB } { 0122 }
      { AC } { 0166 }
      { AE } { 017D }
      { B1 } { 0105 }
      { B2 } { 02DB }
      { B3 } { 0157 }
      { B5 } { 0129 }
      { B6 } { 013C }
      { B7 } { 02C7 }
      { B9 } { 0161 }
      { BA } { 0113 }
      { BB } { 0123 }
      { BC } { 0167 }
      { BD } { 014A }
      { BE } { 017E }
      { BF } { 014B }
      { C0 } { 0100 }
      { C7 } { 012E }
      { C8 } { 010C }
      { CA } { 0118 }
      { CC } { 0116 }
      { CF } { 012A }
      { D0 } { 0110 }
      { D1 } { 0145 }
      { D2 } { 014C }
      { D3 } { 0136 }
      { D9 } { 0172 }
      { DD } { 0168 }
      { DE } { 016A }
      { DF } { 00DF }
      { E0 } { 0101 }
      { E7 } { 012F }
      { E8 } { 010D }
      { EA } { 0119 }
      { EC } { 0117 }
      { EF } { 012B }
      { F0 } { 0111 }
      { F1 } { 0146 }
      { F2 } { 014D }
      { F3 } { 0137 }
      { F9 } { 0173 }
      { FD } { 0169 }
      { FE } { 016B }
      { FF } { 02D9 }
      { \q_stop \prg_map_break: } { }
    \prg_break_point:n { }
  }
%</iso88594>
%    \end{macrocode}
%
% \end{implementation}
%
% \PrintIndex
