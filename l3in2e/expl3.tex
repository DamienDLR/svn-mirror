% Search for %CAR: for comments, etc.
% Introduction now completed:
% CAR: 20/12/97
\documentclass
%        {ltugproc}
{ltxguide}

%CAR: why?
\setlength\hfuzz{10pt}

\usepackage{shortvrb}
\MakeShortVerb{\|}

% A couple of \provide.. so document runs with=20
% both ltugproc and ltxguide classes
%
\providecommand \m [1]{$\langle$\textit{#1}$\rangle$}
\providecommand \netaddress {\date}
\providecommand \acro [1]{\textsc{\MakeLowercase{#1}}}
\providecommand \ie {i.e.,~}
\providecommand \eg {e.g.,~}

\begin{document}
\title{The \LaTeX3 Programming Language---\\
a proposed system for \TeX\ macro programming}


\author{The \LaTeX3 Project}
\netaddress{latex-l@urz.uni-heidelberg.de}



\begin{abstract}
  This paper gives s brief introduction to a new set of programming
  conventions that have been designed to meet the requirements of
  large scale \TeX\ macro programming projects such as \LaTeX.
  (Therefore the system is not suitable either for
  document mark-up or as a style specification language.)

The main features of the system described here are:
\begin{itemize}
\item classification of the macros (or, in \LaTeX{} terminology,
  commands) into \LaTeX{} functions and \LaTeX{} parameters, and also
  into modules containing related commands;
\item  a systematic naming scheme based on these
  classifications;
\item  a simple mechanism for controlling the expansion of a function's
arguments.
\end{itemize}
This system  is under consideration as the basis for \TeX{} programming
within the \LaTeX3 project.

This paper is based on a talk given by David Carlisle in San
Francisco, July 1997, but it describes the work of several people,
principally:
  Frank Mittelbach,
  Denys Duchier,
  Rainer Sch=F6pf,
  Chris Rowley,
  Michael Downes,
  Johannes Braams,
  David Carlisle and
  Alan Jeffrey.
\end{abstract}
%CAR: order of names?
\maketitle


\section{Introduction}

This paper describes the conventions for a \TeX-based programming
language which is intended to provide a more consistent and rational
environment for the construction of large scale \TeX{} macro projects
such as \LaTeX.

Variants of this language have been in use within the \LaTeX3 project
since around 1990 but the syntax specification to be outlined here
should \emph{not} be considered final. This is an experimental
language, thus the syntax conventions and naming schemes may (and
probably will) change as more experience is gained with using the
language in practice.

The next section shows where this language fits into a complete
\TeX-based document processing system.  We then describe the major
features of the syntactic structure of command names, including the
argument specification syntax used in function names.

The practical ideas behind this argument syntax are explained in
Section~\ref{sec:exp}, together with the semantics of the expansion
control mechanism and the interface used to define variant forms of
functions.  Then Section~\ref{sec:access} discusses some advantages of th=
e
syntax for parameter names.

As we shall demonstrate, the use of a structured naming scheme and
variant forms for functions greatly improves the readability of the
code and hence also its reliability.  Experience shows that the longer
command names which result from the new syntax do not make the process
of \emph{writing} the code significantly harder (especially when using
a reasonably intelligent editor).

The final section gives some details about the current experimental
distribution of some of this system.


\section{Languages and interfaces}
\label{sec:langs}

It is possible to identify several distinct languages related to the
various interfaces that are needed in a \TeX-based document processing
system.  This section looks at those we consider most important for
\LaTeX3.

\begin{description}
\item[Document mark-up] This comprises the commands (often called tags)
  that are to embedded in the document (the |.tex| file). It is
  generally accepted that such mark-up should be essentially
  \emph{declarative}.  It may be traditional \TeX-based mark-up such as
  the \LaTeX2, as described in \cite{A-W:LLa94}, or \acro{SGML}-based
  mark-up such as \acro{XML}.
 =20
  One problem with more traditional \TeX\ coding conventions is that
  the names and syntax of \TeX's primitive formatting commands are
  ingeniously designed to be `natural' when used directly by the
  author as document mark-up.  Ironically, the ubiquity (and widely
  recognised superiority) of logical mark-up has meant that such
  explicit formatting commands are almost never needed in documents.
  Thus they are used almost exclusively by \TeX{} programmers to
  define higher-level commands and their idiosyncratic syntax is
  not at all popular with this community.  Moreover, many of them have
  names that could be very useful as document mark-up tags were they
  not pre-empted as primitives (\eg |\box| or |\special|).=20
 =20
\item[Designer interface] This relates a (human) typographic
  designer's specification for a document to a program that `formats
  the document'.  It should ideally use a declarative language that
  facilitates expression of the relationship and spacing rules specified
  for the layout of the various document elements.

  This language is not embedded in document text and it will be very
  different in form to the document mark-up language.  For
  \acro{SGML}-based systems the \acro{DSSSL} language may come to play
  this role.  For \LaTeX, this level was almost completely missing
  from \LaTeX2.09; \LaTeXe\ made some improvements in this area but it
  is still the case that implementing a design specification in
  \LaTeX\ requires far more `low-level' coding than is acceptable.
\item[Programmer interface]=20
  This language is the implementation
  language in which the basic typesetting functionality is
  implemented, building upon the primitives supplied by \TeX\ (or a
  successor program). It may also be used to implement the previous
  two languages `within' \TeX, as in the current \LaTeX\ system.
\end{description}

Only the last of these three interfaces is covered by this paper,
which describes a system aimed at providing a suitable basis for
coding large scale projects in \TeX (but this should not preclude its
use for smaller projects).  Its main distinguishing features are
summarised here.

\begin{itemize}
\item A consistent naming scheme for all commands, including \TeX\
  primitives.
\item The classification of commands as \LaTeX{} functions or \LaTeX{}
  parameters, and also their division into modules according to their
  functionality.
\item A simple mechanism for controlling argument expansion.
\item Provision of a sufficiently rich set of core \LaTeX{} functions
  for handling programming constructs such as: queues, sets,
  stacks, property lists.
\item A \TeX{} programming environment in which, for example, all
  white space ignored.
%CAR: does this last item fit in here?
\end{itemize}

\section{The naming scheme}
\label{sec:scheme}

The naming conventions for this programming language distinguish
between \textit{functions} and \textit{parameters}. Functions can have
arguments and they are executed.  Parameters can be assigned values
and they are used in arguments to functions; they are not directly
executed but are manipulated by mutator and accessor functions.
Functions and parameters with a related functionality (for example
accessing counters, or manipulating lists, etc.)\ are collected into
\textit{modules}.


Note that all these terms are only \LaTeX{} terminology and are not,
for example, intended to indicate that the commands have these
properties when considered in the context of basic \TeX{} or in any
more general programming context.


\subsection{Examples}
\label{sec:ex}

Before giving the details of the naming scheme, here are a few
examples to indicate the flavour of the scheme; first some parameter
names.

%CAR: egs should be from stuff that is available?
%CAR: correct names?  =20
|\l_tmpa_box| is a local parameter (hence the~|l_| prefix)
corresponding to a box register.

|\g_tmpa_box| is a global parameter (hence the~|g_| prefix)
corresponding to a box register.=20

|\c_empty_toks|
is the constant~(|c_|) token register parameter that is for ever empty.


Now here is an example function.

|\seq_push:Nn| is the function which puts the token list specified by
its second argument onto the stack specified by its first argument.
The different natures of the two arguments are indicated by the~|:Nn|
suffix. The first argument must be a single token specifying the name
of the stack parameter: such single-token arguments are denoted~|N|.
The second argument is a normal \TeX\ `non-delimited argument' which
may either be a single token, or a balanced, brace-delimited token
list (which we shall call a \textit{braced token list}: the~|n|
denotes such a `normal' argument form.

% |\cnt_add:Nn| is the function which adds the value specified by its
% second argument to the count register specified by its first argument.
% The different natures of the two arguments are indicated by the~|:Nn|
% suffix. The first argument must be a single token specifying the name
% of the count parameter: such single-token arguments are denoted~|N|.
% The second argument is a normal \TeX\ `non-delimited argument' which
% may either be a single token, or a balanced, brace-delimited
% token list (which we shall call a \textit{braced token list},
% containing an expression for the value to be added: the~|n| denotes
% such a `normal' argument form.


|\seq_push:cn| would be similar to the above, but in this case the
stack is specified in the first argument by a token list that
expands to the \emph{name} of the stack parameter.

These names of these functions indicate that they are in the module
called |seq|.


\subsection{Formal syntax of the conventions}
\label{sec:namesyn}

We shall now look in more detail at the syntax of these names.

The syntax of parameter names is as follows:
 \begin{quote}
   |\|\m{access}|_|\m{module}|_|\m{description}|_|\m{type}
 \end{quote}

The syntax of function names is as follows:
 \begin{quote}
   |\|\m{module}|_|\m{description}|:|\m{arg-spec}
 \end{quote}


\subsection{Modules and descriptions}
\label{sec:modules}

The syntax of all names contains \m{module} and
\m{description}: these both give information about the command.

A \textit{module} is a collection of functions and parameters that are
closely related.

Typical \textit{module} names include~|count| for integer parameters
and related functions,~|seq| for sequences and |box| for boxes.
Packages providing new programming functionality will add new modules
as needed; the programmer can choose any unused name, consisting
of letters only, for a module.

The \textit{description} gives more detailed information about the
function or parameter, and provides a unique name for it.  It should
consist of letters and, possibly,~|_|~characters.

\subsection{Parameters: access and type}
\label{sec:parms}

The \m{access} part of the name describes how the parameter can be
accessed.  Parameters are primarily classified as local, global or
constant (there are further, more technical, classes).  This
\textit{access} type appears as a code at the beginning of the name:
the codes used include:
\begin{itemize}  %CAR: short labels
\item[\bf c \hskip \labelwidth \hss]
  constants (global parameters whose value should not be changed);
\item[\bf g \hskip \labelwidth \hss]
  parameters whose value should only be set globally;
\item[\bf l \hskip \labelwidth \hss]
  parameters whose value should only be set locally.
\end{itemize}
%  As described below, some special access types relate
%  to \TeX\ primitive parameters.
%CAR: no longer true.

The \m{type} will normally (except when introducing a new data-type)
be in the list of available \textit{data-types}; these include the
primitive \TeX\ data-types, such as the various registers, but to
these will be added data-types built within the \LaTeX{} programming
system.

At present, these data-types include:
\begin{description}
\item[count] integer-valued count register;
\item[toks] token register;
\item[box] box register;
\item[fcount] `Fake counter': a data type created to avoid
  problems with the limited number of available count registers in
  (standard) \TeX.
\end{description}

When the \m{type} and \m{module} are identical (as often happens in
the more basic names) the \m{module} part is often omitted for
aesthetic reasons.


\subsection{Functions: argument specifications}
\label{sec:args}

 Function names end with an \m{arg-spec} after a colon.  This
 gives an indication of the types of argument that a function takes,
 and provides a convenient method of naming similar functions that
 differ only in their argument forms (see Section~\ref{sec:exp} for
 examples).

 The \m{arg-spec} consists of a (possibly empty) list of characters
 each denoting one argument of the function.  It is important to
 understand that `argument' here refers to the effective argument of
 the \LaTeX{} function, not to an argument at the \TeX-level.  Indeed,
 the top level \TeX\ macro that has this name typically has no
 arguments.  This is an extension of the existing \LaTeX\ convention
 where one says that |\section| has an optional argument and a
 mandatory argument, whereas the \TeX\ macro |\section| actually has
 zero parameters at the \TeX\ level, it merely calls an internal \LaTeX\
 command which in turn calls others that look ahead for star forms and
 optional arguments.

The list of possible argument specifiers includes the following.
\begin{description}
\item[n]  Unexpanded token or braced token list.\\
  This is a standard \TeX\ undelimited macro argument.
\item[o]  One-level-expanded token or braced token list.\\ =20
  this means that the argument is expanded one level, as is done by
  |\expandafter|, and the expansion is passed to the function as a braced
  token list.  Note that if the original argument is a braced
  token list then only the first token in that list is expanded.
\item[x]  Fully-expanded token or braced token list.\\
  This means that the argument is expanded as in the replacement text of
  an~|\edef|, and the expansion is passed to the function as a
  braced token list.
\item[c]  Character string used as a command name.\\
  The argument (a token or braced token list) should
  expand to a sequence of characters which is then used to construct a
  command name (via~|\csname|, |\endcsname|). This single=20
  token is passed as the argument to the function.
\item[N]  Single token (unlike~|n|, the argument must not be
  surrounded by braces).\\
  A typical example of a command taking an~|N|
  argument is~|\def|, in which the command being defined must be
  unbraced.
 \item[O]  Single one-level-expanded token (unbraced).\\
   As for+~|o|, the one-level expansion is passed (as a
   braced token list) to the function.
 \item[X]  Single fully expanded token (unbraced).\\
   As for~|x|, the full expansion is passed (as a
   braced token list) to the function.
 \item[C]  Character string used as a command name then one-level expande=
d.\\
   The form of the argument is exactly as for~|c|, but the
   resulting token is then expanded one level (as for~|O|), and
   the expansion is passed to the function as a braced token list.
 \item[p]  Primitive \TeX\ parameter specification.\\
   This can be something simple like~|#1#2#3|, but may use arbitrary
   delimited argument syntax such as |#1,#2\q_stop#3|.
 \item[T,F] These are special cases of~|n| arguments, used for the
   true and false code in conditional commands.
\end{description}

There are two other specifiers with more general meanings:
\begin{description}
\item[D] This means: \textbf{Do not use}.  This special case is used
  for \TeX\ primitives and other commands that are provided for use
  only while bootstrapping the \LaTeX\ kernel.  If the \TeX\ primitive
  needs to be used in other contexts it will be given an alternative,
  more appropriate, name with a useful argument specification.  The
  argument syntax of these is often weird.
 \item[w] This also means that the argument syntax is `weird'.  It is
   used for functions with arguments that take non standard forms,
   usually delimited arguments.  These are needed to implement certain
   modules.
%CAR: no longer true?
%    and also the boolean tests of many of the primitive
%    |\if|\ldots\ tests.
\end{description}


\section{Expansion control}
\label{sec:exp}

\subsection{Simpler means better}
\label{sec;simpler}

Anyone who programs in \TeX\ is frustratingly familiar with the
problem of arranging that arguments to functions are suitably expanded
before the function is called.  To illustrate how expansion control
can bring instant relief to this problem we shall consider two
examples copied from \texttt{latex.ltx}.

\begin{verbatim}
\global
  \expandafter
    \expandafter
  \expandafter
      \let
  \expandafter
     \reserved@a
  \csname \curr@fontshape \endcsname
\end{verbatim}
This first piece of code is in essence simply a
global~|\let|. However, the token to be defined is obtained by
expanding |\reserved@a| one level; and, worse, the token to which it
is to be let is obtained by fully expanding |\curr@fontshape| and then
using the characters produced by that expansion to construct a command
name.  The result is a mess of interwoven |\expandafter| and~|\csname|
beloved of all \TeX\ programmers, and the code is essentially
unreadable.

Using the conventions outlined here, the task would be achieved with
code such as this:
\begin{verbatim}
\glet:Oc
  \g_reserved_a_tlp \l_current_font_shape_tlp
\end{verbatim}
The command |\glet:Oc| is a global~|\let| that expands its
first argument once, and generates a command name out of its second
argument, before making the definition. This produces code that
is far more readable and more likely to be correct first time.

Here is the second example.
\begin{verbatim}
\expandafter
  \in@
\csname sym#3%
  \expandafter
    \endcsname
  \expandafter
    {%
  \group@list}%
\end{verbatim}
This piece of code is part of the definition of another function. It
first produces two things: a token list, expanding |\group@list| once;
and a token whose name comes from~`|sym#3|'.  Then the function~|\in@|
is called and this tests if its first argument occurs in the token list
of its second argument.

Again we can improve enormously on the code.  First we shall rename the
function~|\in@| according to our conventions.  A function taking
two normal `\texttt{n}' arguments might reasonably be named
|\test_if_in:nn|; thus the variant function we need will be=20
defined with the appropriate argument types and its name will be
|\test_if_in:cO|.  Now this code fragment will be simply:

\begin{verbatim}
\test_if_in:co {sym#3} \group_list:
\end{verbatim}
Note that, in addition to the lack of |\expandafter|, the space after
the~|}| will be silently ignored since all white space is ignored in
this programming environment.
%CAR: does not seem to fit well here, but where should it be?


\subsection{New functions from old}
\label{sec:newfunc}

For many common functions the \LaTeX3 kernel will provide variants
with a range of argument forms, and similarly it is expected that
extension packages providing new functions will make then available in
the all the commonly needed forms.

However, there will be occasions where it is necessary to construct a
new such variant form so the expansion module provides a
straightforward mechanism for the creation of functions with any
required argument type, starting from a function that takes `normal'
\TeX\ delimited arguments.

To illustrate this let us suppose you have a `base function'
|\demo_cmd:nnn| that takes three normal arguments, and you need to
construct the variant~|\cmd:cnx|, for which the first argument is used
to construct the \emph{name} of a command, whilst the third argument
must be fully expanded before being passed to~|\cmd:nnn|.

To produce this form from the base form, simply define |\demo_cmd:cnx|
as follows:
\begin{verbatim}
\def:Npn \demo_cmd:cnx
  {\exp_args:Ncnx \demo_cmd:nnn}
\end{verbatim}
The creator function |\exp_args:Ncnx| has as its first~(\texttt{N})
argument the base function and it processes the next three arguments
as required for the variant form: it applies the~|\csname|
construction to the first, and acts on the third with~|\edef|.  It
then constructs a call to the base function with these suitably
transformed arguments.

Now you can write, for example:
\begin{verbatim}
\demo_cmd:cnx {abc} {pq} {\rst \xyz }
\end{verbatim}
rather than \ldots\ well, something like this!
\begin{verbatim}
\edef \temp {\rst \xyz }
\expandafter
  \demo_cmd=20
\csname abc%
  \expandafter
    \endcsname
  \expandafter
    {%
  \expandafter
    p%
  \expandafter
    q%
  \expandafter
    }%
  \expandafter
    {%
  \temp}
\end{verbatim}

A large range of similar argument processing functions are available=20
but even if you need a particular argument combination for which such
a function is not provided help is at hand.

For example, you may one day wish to construct this argument
processing function |\exp_args:Nxcxcxc| for a function that fully
expands arguments 1,~3 and~5, and produces commands to pass as
arguments 2,~4 and~6 using~|\csname|. The definition you need is simply
\begin{verbatim}
\def:Npn \exp_args:Nxcxcxc=20
  {\::x \::c \::x \::c \::x \::c \:::}
\end{verbatim}
Similar functions~(|\::n|, |\::o|, |\::N| and |\::C|) exist for the
other argument types, and they may be strung together in the required
order (terminated by~|\:::|) to create a function which processes
arguments in the desired way.
%CAR: say why \::O and \::X are not available?

\section{Parameter assignments and accessor functions}
\label{sec:access}
%CAR: I have not checked all the details here.

\subsection{Checking assignments}
\label{sec:check}

One of the advantages of having a consistent scheme is that the system
can provide more extensive error checking and debugging facilities.
For example, an accessor function that makes a \emph{global}
assignment of a value to a parameter can check that it is not passed
the name of a \emph{local} parameter as that argument: it does this by
checking that the name starts with~|\g_|.

Such checking is probably too slow for normal use, but the code can
have hooks built in that allow a format to be made in which all
functions perform this kind of check. A typical section of the source
for such code might look like this (recall that white space is ignored):
\begin{verbatim}
%<*!check>
\let_new:NN=20
  \toks_gset:Nn \pref_global:D
%</!check>
%<*check>
\def_new:Npn \toks_gset:Nn #1
  {
  \chk_global:N #1
  \pref_global:D #1
  }
%</check>
\end{verbatim}
In the above code the function |\toks_gset:Nn| takes a single
token~(|N|) specifying a token register, and globally sets it to the
value passed in the second argument. So a typical use of it would be:
\begin{verbatim}
\toks_gset \g_xxx_toks {<some value>}
\end{verbatim}
In the normal definition, |\toks_gset| can be simply~|\let|
to~|\global| because the primitive \TeX{} token register does not
require any explicit assignment function:
this is done by the |%<*!check>| code above.
However, the alternative definition first checks that the argument
passed as~|#1| is the name of a global parameter and raises an error
if it is not.  It does this by taking apart the command name passed
as~|#1| and checking that it starts~|\g_|.

\subsection{Consistency}
\label{sec:cons}

The primitive \TeX\ syntax for register assignments has a very minimal
syntax and, apart from box functions, there are no explicit functions
for assigning values to these registers.  This makes it impossible
to implement alternative data-types with a syntax that is both
consistent and at all similar to the syntax for the primitives;
moreover, it encourages a coding style that is very error prone.

As in the |\toks_gset:Nn| example given above, all \LaTeX\ data-types
are provided with explicit functions for assignment and for use, even
when these have essentially empty definitions.  This allows for better
error checking as described above; it also allows the construction of
further data-types with a similar interface, even when the
implementation of the associated functions is very complex.

For example, the `fake-counter' data-type (mentioned in
Section~\ref{sec:parms} will appear at the \LaTeX{} programming level
to be exactly like the data-type based on primitive count registers;
however, internally it makes no use of count registers.  Typical
functions in this module are illustrated here.

\begin{quote}
\verb|\fcount_new:N \l_tmpa_fcount|\\
This declares the local parameter |\l_example_fcount| as a fake counter.

\verb|\fcount_add:Nn \l_example_fcount \c_thirty_two|\\
This increments the value of this fake counter by 32. =20
\end{quote}
%CAR: This does not make much sense without the cnt stuff!

\section{The experimental distribution}
\label{sec:dist}

The initial implementations of a \LaTeX\ programming language using
this kind of syntax remain unreleased (and not completely functional);
they largely pre-date \LaTeXe!  The current distribution provides a
subset of the functionality of those implementations, in the form of
packages to be used on top of \LaTeXe.

The intention is to allow experienced \TeX\ programmers to experiment
with the system and to comment on the interface. This means that
\textbf{\itshape the interface will change}. No part of this system,
including the name of anything, should be relied upon as being
available in a later release.  Please do \emph{experiment} with these
packages, but do \emph{not} use them for code that you expect to keep
unchanged over a long period.

In view of the intended experimental use for this distribution, we
have currently produced only a few modules for use with \LaTeXe.
These set up the conventions and implement a few basic programming
constructs, such as token-lists and sequences.  They are intended
only to give a flavour of the code: the full \LaTeX3 kernel will
provide a very rich set of programming constructs so that packages can
efficiently share code, in contrast with the situation in the current
\LaTeX\ where every large package must implement its own version of
queues, stacks, etc., as necessary.

The currently available packages are described briefly here.
\begin{description}
\item[l3names] This sets up the basic naming scheme and renames all
the \TeX\ primitives.  If it is loaded with the option
\texttt{[removeoldnames]} then the old primitive names such as~|\box|
become \emph{undefined} and are thus made available for user
definitions. Caution: use of this option will probably break existing
\TeX\ code!

\item [l3basics]
This contains basic definition modules that are used
by the other packages.

\item[l3chk]
This contains Functions that check (and make) definitions, comparable
to the existing |\newcommand| or |\renewcommand|.

\item[l3tlp]
This implements a basic data-type, called a \textit{token-list
pointer}, used for storing named token lists: these are essentially
\TeX{} macros with no arguments.

\item[l3expan] This is the argument expansion module discussed in
Section~\ref{sec:exp}.

\item[l3quark] A `quark' is a command that is defined to expand to
itself!  Therefore they must never be expanded as this will generate
infinite recursion; they do nevertheless have many uses, \eg as
special markers and delimiters within code.
%CAR: this should maybe go somewhere else, but where?

\item[l3seq]
This implements data-types such as queues and stacks.

\item[l3prop]
This implements the data-type for `property lists' that are used, in
particular, for storing key/value pairs.
\end{description}

The distribution also contains the \LaTeX\ source for the latest
version of this document, a docstrip install file and two small test
files.

\begin{thebibliography}{1}

\bibitem{A-W:LLa94}
Leslie Lamport.
\newblock {\em {\LaTeX:} A Document Preparation System}.
\newblock Addison-Wesley, Reading, Massachusetts, second edition, 1994.

%CAR: more refs?
%  eg: LaTeX3 info;
%  CTAN sources
\end{thebibliography}

\end{document}

